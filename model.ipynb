{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRS (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import icecream as ic\n",
    "\n",
    "utils.seed_everything(42)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/merged_data_processed.csv')\n",
    "unreviewed_products_df = pd.read_csv('data/unreviewed_products_processed.csv')\n",
    "products_df = pd.read_csv('data/products_sampled_processed.csv')\n",
    "reviews_df = pd.read_csv('data/reviews_sampled_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (47238, 48)\n",
      "Shape of unreviewed_products_df: (22903, 41)\n",
      "Shape of products_df: (35246, 41)\n",
      "Shape of reviews_df: (45538, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of df: {df.shape}')\n",
    "print(f'Shape of unreviewed_products_df: {unreviewed_products_df.shape}')\n",
    "print(f'Shape of products_df: {products_df.shape}')\n",
    "print(f'Shape of reviews_df: {reviews_df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 34211\n",
      "Number of unique users: 1000\n",
      "Number of unique reviewed products: 11369\n",
      "Number of unique unreviewed products: 22842\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique products: {products_df[\"asin\"].nunique()}')\n",
    "print(f'Number of unique users: {reviews_df[\"reviewerID\"].nunique()}')\n",
    "print(f'Number of unique reviewed products: {df[\"asin\"].nunique()}')\n",
    "print(f'Number of unique unreviewed products: {unreviewed_products_df[\"asin\"].nunique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data preparation for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User and product id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user and item mappings\n",
    "user_mapping = {user_id: index for index, user_id in enumerate(df['reviewerID'].unique())}\n",
    "item_mapping = {item_id: index for index, item_id in enumerate(products_df['asin'].unique())}\n",
    "\n",
    "reviewed_item_mapping = {item_id: index for index, item_id in enumerate(df['asin'].unique())}\n",
    "\n",
    "# Map user and item IDs to indices\n",
    "df['user_index'] = df['reviewerID'].map(user_mapping)\n",
    "df['item_index'] = df['asin'].map(reviewed_item_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User-item matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_product_matrix = pd.pivot_table(df, values='overall', index='reviewerID', columns='asin', fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings (with Word2Vec or whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Create embeddings using Word2Vec\n",
    "def create_word2vec_embeddings(texts, embedding_dim):\n",
    "  # Tokenize the texts\n",
    "  tokenized_texts = [text.split() for text in texts]\n",
    "  \n",
    "  # Train Word2Vec model\n",
    "  model = Word2Vec(tokenized_texts, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "  \n",
    "  # Get the embeddings for each text\n",
    "  embeddings = []\n",
    "  for text in tokenized_texts:\n",
    "      embedding = np.mean([model.wv[word] for word in text if word in model.wv], axis=0)\n",
    "      embeddings.append(embedding)\n",
    "  \n",
    "  return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for textual data\n",
    "review_embeddings = create_word2vec_embeddings(df['reviewText'], embedding_dim=100)\n",
    "title_embeddings = create_word2vec_embeddings(df['title'], embedding_dim=100)\n",
    "description_embeddings = create_word2vec_embeddings(df['description'], embedding_dim=100)\n",
    "summary_embeddings = create_word2vec_embeddings(df['summary'], embedding_dim=100)\n",
    "feature_embeddings = create_word2vec_embeddings(df['feature'], embedding_dim=100)\n",
    "brand_embeddings = create_word2vec_embeddings(df['brand'], embedding_dim=100)\n",
    "\n",
    "\n",
    "#load the embeddings\n",
    "# review_embeddings = torch.load('data/embeds/review_embeddings.pt')\n",
    "# summary_embeddings = torch.load('data/embeds/summary_embeddings.pt')\n",
    "# description_embeddings = torch.load('data/embeds/description_embeddings.pt')\n",
    "# title_embeddings = torch.load('data/embeds/title_embeddings.pt')\n",
    "# feature_embeddings = torch.load('data/embeds/feature_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed (SVD) from user-matrix pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_embeddings(user_item_matrix: pd.DataFrame, embedding_length):\n",
    "    \"\"\"\n",
    "    Apply SVD to the user-item matrix to obtain user and item embeddings.\n",
    "    U = m x r orthogonal left singular matrix, which represents the relationship between users and latent factors\n",
    "    S = r x r diagonal matrix, which describes the strength of each latent factor\n",
    "    V = r x n diagonal right singular matrix, which indicates the similarity between items and latent factors\n",
    "    \n",
    "    :param user_item_matrix: user-item matrix\n",
    "    :param embedding_length: number of latent factors, which is the dimensionality of the reduced space\n",
    "    \"\"\"\n",
    "    from scipy.sparse.linalg import svds\n",
    "    \n",
    "    # transpose the matrix to obtain the item-user matrix\n",
    "    # (this due to the large number of items compared to users)\n",
    "    matrix = user_item_matrix.values\n",
    "\n",
    "    U, Sigma, VT = svds(matrix, k=embedding_length)\n",
    "    user_embed_df = pd.DataFrame(U, index = user_item_matrix.index)\n",
    "    VT_T = np.transpose(VT)\n",
    "    item_embed_df = pd.DataFrame(VT_T, index=user_item_matrix.columns)\n",
    "    \n",
    "    return user_embed_df, item_embed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed_df, item_embed_df = SVD_embeddings(user_product_matrix, 800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders for the Pytorch-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "# class for the dataset\n",
    "class AmazonReviewDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, ratings, review_texts, product_titles, product_descriptions, review_summary, product_feature):\n",
    "        self.user_ids = user_ids\n",
    "        self.item_ids = item_ids\n",
    "        self.ratings = ratings\n",
    "        self.review_texts = review_texts\n",
    "        self.product_titles = product_titles\n",
    "        self.product_descriptions = product_descriptions\n",
    "        self.review_summary = review_summary\n",
    "        self.product_feature = product_feature\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        item_id = self.item_ids[index]\n",
    "        rating = self.ratings[index]\n",
    "        review_text = self.review_texts[index]\n",
    "        product_title = self.product_titles[index]\n",
    "        product_description = self.product_descriptions[index]\n",
    "        review_summary = self.review_summary[index]\n",
    "        product_feature = self.product_feature[index]\n",
    "        return user_id, item_id, rating, review_text, product_title, product_description, review_summary, product_feature\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = AmazonReviewDataset(\n",
    "    train_data['user_index'].values,\n",
    "    train_data['item_index'].values,\n",
    "    train_data['overall'].values,\n",
    "    review_embeddings[train_data.index],\n",
    "    title_embeddings[train_data.index],\n",
    "    description_embeddings[train_data.index],\n",
    "    summary_embeddings[train_data.index],\n",
    "    feature_embeddings[train_data.index]\n",
    ")\n",
    "\n",
    "test_dataset = AmazonReviewDataset(\n",
    "    test_data['user_index'].values,\n",
    "    test_data['item_index'].values,\n",
    "    test_data['overall'].values,\n",
    "    review_embeddings[test_data.index],\n",
    "    title_embeddings[test_data.index],\n",
    "    description_embeddings[test_data.index],\n",
    "    summary_embeddings[test_data.index],\n",
    "    feature_embeddings[test_data.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A100WO06OQR8BQ and item B000034DLQ: 0.03378242774955097\n"
     ]
    }
   ],
   "source": [
    "# predictions with the the obrained SVD embeddings\n",
    "def predict_ratings(user_embed_df: pd.DataFrame, item_embed_df: pd.DataFrame, user_id: str, item_id: str):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given user and item.\n",
    "    \n",
    "    :param user_embed_df: user embeddings\n",
    "    :param item_embed_df: item embeddings\n",
    "    :param user_id: user id\n",
    "    :param item_id: item id\n",
    "    \"\"\"\n",
    "    user_embedding = user_embed_df.loc[user_id]\n",
    "    item_embedding = item_embed_df.loc[item_id]\n",
    "    \n",
    "    \n",
    "    rating = np.dot(user_embedding, item_embedding)\n",
    "    return rating\n",
    "\n",
    "# example of prediction with a an item rated by a user\n",
    "user_id = user_product_matrix.index[0]\n",
    "\n",
    "# take the first product id rated by \"user_id\"\n",
    "# (thus an element that is not 0 in the user-product matrix)\n",
    "item_id = user_product_matrix.columns[user_product_matrix.loc[user_id] != 0].values[0]\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_ratings(user_embed_df, item_embed_df, user_id, item_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the predictions are consistent with the actual ratings\n",
    "actual_rating = user_product_matrix.loc[user_id, item_id]\n",
    "\n",
    "actual_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.95599866e-04,  2.59605406e-03, -2.15158369e-03, ...,\n",
       "         6.22025910e-03,  1.38991908e-03,  1.72065874e-04],\n",
       "       [-1.25936316e-04, -1.79447050e-03, -6.46746476e-04, ...,\n",
       "        -1.97749373e-03, -4.30993638e-04,  2.06622559e-04],\n",
       "       [-1.01736420e-03,  1.07401753e-03,  9.87496629e-04, ...,\n",
       "        -1.70572371e-03, -2.46175998e-03,  3.14422151e-04],\n",
       "       ...,\n",
       "       [-7.58173883e-05, -6.56917060e-04, -1.00105554e-03, ...,\n",
       "         5.08348811e-04,  2.41673356e-03,  5.65461859e-04],\n",
       "       [-7.90054976e-03,  9.44410429e-04,  1.71045655e-03, ...,\n",
       "        -4.22877202e-03, -1.23563660e-04, -3.78508327e-04],\n",
       "       [-2.05917440e-03,  1.79413998e-03,  7.98745975e-04, ...,\n",
       "         1.14776802e-04, -4.45360286e-03, -3.12577453e-05]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_embed_df, item_embed_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model test with SVD from scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick performance check of SVD by using scikit-surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7016\n",
      "RMSE: 0.7237\n",
      "RMSE: 0.7014\n",
      "RMSE: 0.7050\n",
      "RMSE: 0.7201\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly, Dataset, SVD, Reader, accuracy, Trainset\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_test = Dataset.load_from_df(df[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data_test, test_size=0.25)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data_test):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'A1HBTW5M7ZZ9PT'\n",
    "test_user = reviews_df[reviews_df['reviewerID'] == user_id]\n",
    "item_id = 'B00006IEI7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: A1HBTW5M7ZZ9PT item: B00006IEI7 r_ui = 5.00   est = 4.70   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(user_id, item_id, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_dims, output_dim, text_embedding_dims):\n",
    "        super(NCF, self).__init__()\n",
    "        \n",
    "        # embedding layers for the users and items ids\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Additional input layers for each type of text embedding\n",
    "        # (the text embeddings will be passed through an additional \n",
    "        # linear layer (text_embedding_layer) to project them into \n",
    "        # the same embedding space as the user and item embeddings)\n",
    "        self.text_embedding_layers = nn.ModuleList()\n",
    "        for text_embedding_dim in text_embedding_dims:\n",
    "            self.text_embedding_layers.append(nn.Linear(text_embedding_dim, embedding_dim))\n",
    "        \n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_dim = embedding_dim * 2\n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            self.fc_layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids, text_embeddings):\n",
    "        user_embeddings = self.user_embedding(user_ids)\n",
    "        item_embeddings = self.item_embedding(item_ids)\n",
    "        \n",
    "        # Project each type of text embedding to the same embedding space\n",
    "        text_embs = []\n",
    "        for i, text_embedding in enumerate(text_embeddings):\n",
    "            text_emb = self.text_embedding_layers[i](text_embedding)\n",
    "            text_embs.append(text_emb)\n",
    "        \n",
    "        x = torch.cat([user_embeddings, item_embeddings, *text_embs], dim=1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NCF model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for user_ids, item_ids, ratings, _, _, _, _, _ in progress_bar:\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            loss = criterion(outputs.squeeze(), ratings.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "            \n",
    "        \n",
    "            \n",
    "# Evaluate the NCF model\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\")\n",
    "        for user_ids, item_ids, ratings, _, _, _, _, _ in progress_bar:\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            true_ratings.extend(ratings.tolist())\n",
    "\n",
    "    mse = mean_squared_error(true_ratings, predictions)\n",
    "    mae = mean_absolute_error(true_ratings, predictions)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 591/591 [00:03<00:00, 172.85batch/s, loss=1.78]\n",
      "Epoch 2/10: 100%|██████████| 591/591 [00:03<00:00, 182.18batch/s, loss=0.574]\n",
      "Epoch 3/10: 100%|██████████| 591/591 [00:03<00:00, 181.84batch/s, loss=0.48]  \n",
      "Epoch 4/10: 100%|██████████| 591/591 [00:03<00:00, 175.80batch/s, loss=0.421] \n",
      "Epoch 5/10: 100%|██████████| 591/591 [00:03<00:00, 170.41batch/s, loss=0.371] \n",
      "Epoch 6/10: 100%|██████████| 591/591 [00:03<00:00, 171.00batch/s, loss=0.325] \n",
      "Epoch 7/10: 100%|██████████| 591/591 [00:03<00:00, 173.27batch/s, loss=0.28]  \n",
      "Epoch 8/10: 100%|██████████| 591/591 [00:03<00:00, 173.00batch/s, loss=0.239] \n",
      "Epoch 9/10: 100%|██████████| 591/591 [00:03<00:00, 169.81batch/s, loss=0.201] \n",
      "Epoch 10/10: 100%|██████████| 591/591 [00:03<00:00, 171.08batch/s, loss=0.167] \n",
      "Evaluating: 100%|██████████| 148/148 [00:00<00:00, 1374.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.8271\n",
      "Test MAE: 0.5718\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Create the NCF model\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(reviewed_item_mapping)\n",
    "embedding_dim = 100\n",
    "hidden_dims = [64, 32]\n",
    "output_dim = 1\n",
    "\n",
    "model = NCF(num_users, num_items, embedding_dim, hidden_dims, output_dim).to(device)\n",
    "\n",
    "# Define loss function (RMSE) and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_model(model, train_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "print('\\n')\n",
    "mse, mae = evaluate_model(model, test_loader, device)\n",
    "rmse = torch.sqrt(torch.tensor(mse))\n",
    "print(f\"Test RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model test with single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[59], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m         score \u001b[38;5;241m=\u001b[39m model(user_tensor, item_tensor)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted rating for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mpredict_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB0006HXE1E\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43muser_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mitem_mapping\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;250;43m \u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(f'Actual rating: {user_product_matrix.loc[user_id, item_id]}')\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[59], line 13\u001b[0m, in \u001b[0;36mpredict_score\u001b[0;34m(user_id, item_id, model, user_mapping, item_mapping, device)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 13\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m score\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[44], line 19\u001b[0m, in \u001b[0;36mNCF.forward\u001b[0;34m(self, user_ids, item_ids)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, user_ids, item_ids):\n\u001b[1;32m     18\u001b[0m     user_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding(user_ids)\n\u001b[0;32m---> 19\u001b[0m     item_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([user_embeddings, item_embeddings], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_layers:\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "def predict_score(user_id, item_id, model, user_mapping, item_mapping, device):\n",
    "    # Convert user ID and item ID to their corresponding indices\n",
    "    user_index = user_mapping[user_id]\n",
    "    item_index = item_mapping[item_id]\n",
    "\n",
    "    # Convert indices to tensors\n",
    "    user_tensor = torch.tensor([user_index], dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor([item_index], dtype=torch.long).to(device)\n",
    "\n",
    "    # Get the predicted score from the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        score = model(user_tensor, item_tensor).item()\n",
    "\n",
    "    return score\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_score(user_id, 'B0006HXE1E', model, user_mapping, item_mapping, device)}')\n",
    "# print(f'Actual rating: {user_product_matrix.loc[user_id, item_id]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>dayDifferenceReview</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>productPublishedDate</th>\n",
       "      <th>main_cat_All Beauty</th>\n",
       "      <th>main_cat_All Electronics</th>\n",
       "      <th>main_cat_Amazon Home</th>\n",
       "      <th>main_cat_Arts, Crafts &amp; Sewing</th>\n",
       "      <th>main_cat_Arts, Crafts &amp;amp; Sewing</th>\n",
       "      <th>main_cat_Automotive</th>\n",
       "      <th>main_cat_Baby</th>\n",
       "      <th>main_cat_Books</th>\n",
       "      <th>main_cat_Camera &amp; Photo</th>\n",
       "      <th>main_cat_Camera &amp;amp; Photo</th>\n",
       "      <th>main_cat_Car Electronics</th>\n",
       "      <th>main_cat_Cell Phones &amp; Accessories</th>\n",
       "      <th>main_cat_Cell Phones &amp;amp; Accessories</th>\n",
       "      <th>main_cat_Computers</th>\n",
       "      <th>main_cat_Gift Cards</th>\n",
       "      <th>main_cat_Grocery</th>\n",
       "      <th>main_cat_Health &amp; Personal Care</th>\n",
       "      <th>main_cat_Home Audio &amp; Theater</th>\n",
       "      <th>main_cat_Home Audio &amp;amp; Theater</th>\n",
       "      <th>main_cat_Industrial &amp; Scientific</th>\n",
       "      <th>main_cat_Industrial &amp;amp; Scientific</th>\n",
       "      <th>main_cat_Musical Instruments</th>\n",
       "      <th>main_cat_Office Products</th>\n",
       "      <th>main_cat_Pet Supplies</th>\n",
       "      <th>main_cat_Portable Audio &amp; Accessories</th>\n",
       "      <th>main_cat_Software</th>\n",
       "      <th>main_cat_Sports &amp; Outdoors</th>\n",
       "      <th>main_cat_Sports &amp;amp; Outdoors</th>\n",
       "      <th>main_cat_Tools &amp; Home Improvement</th>\n",
       "      <th>main_cat_Tools &amp;amp; Home Improvement</th>\n",
       "      <th>main_cat_Toys &amp; Games</th>\n",
       "      <th>main_cat_Toys &amp;amp; Games</th>\n",
       "      <th>main_cat_Video Games</th>\n",
       "      <th>dayDifferenceProduct</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4581</th>\n",
       "      <td>3.0</td>\n",
       "      <td>November 06, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IE7Y</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>still search perfect pen</td>\n",
       "      <td>okay</td>\n",
       "      <td>0.933793</td>\n",
       "      <td>lic stic ball pen retractable affordable bic c...</td>\n",
       "      <td>bic csm11blu clic stic retractable ball pen me...</td>\n",
       "      <td>bic</td>\n",
       "      <td>retractable affordable bic classic comfortable...</td>\n",
       "      <td>29</td>\n",
       "      <td>November 27, 2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596844</td>\n",
       "      <td>812</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>3.0</td>\n",
       "      <td>November 06, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IE7Y</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>still search perfect pen</td>\n",
       "      <td>okay</td>\n",
       "      <td>0.933793</td>\n",
       "      <td>lic stic ball pen retractable affordable bic c...</td>\n",
       "      <td>bic csm11blu clic stic retractable ball pen me...</td>\n",
       "      <td>bic</td>\n",
       "      <td>retractable affordable bic classic comfortable...</td>\n",
       "      <td>29</td>\n",
       "      <td>November 27, 2004</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.596844</td>\n",
       "      <td>812</td>\n",
       "      <td>514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12641</th>\n",
       "      <td>3.0</td>\n",
       "      <td>April 14, 2018</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B0006HXE1E</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>liked product bit surprised thin folder used m...</td>\n",
       "      <td>used make privacy folder student</td>\n",
       "      <td>0.984029</td>\n",
       "      <td>endaflex file folder perfect everyday filing n...</td>\n",
       "      <td>pendaflex file folder letter size manila 13 cu...</td>\n",
       "      <td>pendaflex</td>\n",
       "      <td>standard manila folder suit filing system 13cu...</td>\n",
       "      <td>27</td>\n",
       "      <td>September 09, 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.685299</td>\n",
       "      <td>812</td>\n",
       "      <td>1329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15802</th>\n",
       "      <td>3.0</td>\n",
       "      <td>August 05, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B000MK4RAM</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>go wrong easily find alternative dollar tree</td>\n",
       "      <td>good buy find much cheaper dollar tree</td>\n",
       "      <td>0.891901</td>\n",
       "      <td>se flag mark important point textbook document...</td>\n",
       "      <td>postit flag value pack assorted color stick se...</td>\n",
       "      <td>postit</td>\n",
       "      <td>mark tab highlight colorcode flag removable re...</td>\n",
       "      <td>1</td>\n",
       "      <td>October 17, 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.955615</td>\n",
       "      <td>812</td>\n",
       "      <td>2228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31476</th>\n",
       "      <td>3.0</td>\n",
       "      <td>October 01, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00BUI5QWS</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>update february 2016 second laminator started ...</td>\n",
       "      <td>great buy</td>\n",
       "      <td>0.896999</td>\n",
       "      <td>mazon bran</td>\n",
       "      <td>amazonbasics thermal laminator</td>\n",
       "      <td>amazonbasics</td>\n",
       "      <td>laminate document 9 inch wide compatible lette...</td>\n",
       "      <td>56</td>\n",
       "      <td>June 01, 2013</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814403</td>\n",
       "      <td>812</td>\n",
       "      <td>6571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       overall         reviewTime      reviewerID        asin reviewerName                                         reviewText                                 summary  dayDifferenceReview                                        description                                              title         brand                                            feature  rank productPublishedDate  main_cat_All Beauty  main_cat_All Electronics  main_cat_Amazon Home  main_cat_Arts, Crafts & Sewing  main_cat_Arts, Crafts &amp; Sewing  main_cat_Automotive  main_cat_Baby  main_cat_Books  main_cat_Camera & Photo  main_cat_Camera &amp; Photo  main_cat_Car Electronics  main_cat_Cell Phones & Accessories  main_cat_Cell Phones &amp; Accessories  main_cat_Computers  main_cat_Gift Cards  main_cat_Grocery  main_cat_Health & Personal Care  main_cat_Home Audio & Theater  main_cat_Home Audio &amp; Theater  main_cat_Industrial & Scientific  main_cat_Industrial &amp; Scientific  main_cat_Musical Instruments  main_cat_Office Products  main_cat_Pet Supplies  main_cat_Portable Audio & Accessories  main_cat_Software  main_cat_Sports & Outdoors  main_cat_Sports &amp; Outdoors  main_cat_Tools & Home Improvement  main_cat_Tools &amp; Home Improvement  main_cat_Toys & Games  main_cat_Toys &amp; Games  main_cat_Video Games  dayDifferenceProduct  user_index  item_index\n",
       "4581       3.0  November 06, 2016  A1HBTW5M7ZZ9PT  B00006IE7Y        FTLOE                           still search perfect pen                                    okay             0.933793  lic stic ball pen retractable affordable bic c...  bic csm11blu clic stic retractable ball pen me...           bic  retractable affordable bic classic comfortable...    29    November 27, 2004                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.596844         812         514\n",
       "4582       3.0  November 06, 2016  A1HBTW5M7ZZ9PT  B00006IE7Y        FTLOE                           still search perfect pen                                    okay             0.933793  lic stic ball pen retractable affordable bic c...  bic csm11blu clic stic retractable ball pen me...           bic  retractable affordable bic classic comfortable...    29    November 27, 2004                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.596844         812         514\n",
       "12641      3.0     April 14, 2018  A1HBTW5M7ZZ9PT  B0006HXE1E        FTLOE  liked product bit surprised thin folder used m...        used make privacy folder student             0.984029  endaflex file folder perfect everyday filing n...  pendaflex file folder letter size manila 13 cu...     pendaflex  standard manila folder suit filing system 13cu...    27   September 09, 2008                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.685299         812        1329\n",
       "15802      3.0    August 05, 2015  A1HBTW5M7ZZ9PT  B000MK4RAM        FTLOE       go wrong easily find alternative dollar tree  good buy find much cheaper dollar tree             0.891901  se flag mark important point textbook document...  postit flag value pack assorted color stick se...        postit  mark tab highlight colorcode flag removable re...     1     October 17, 2017                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.955615         812        2228\n",
       "31476      3.0   October 01, 2015  A1HBTW5M7ZZ9PT  B00BUI5QWS        FTLOE  update february 2016 second laminator started ...                               great buy             0.896999                                         mazon bran                     amazonbasics thermal laminator  amazonbasics  laminate document 9 inch wide compatible lette...    56        June 01, 2013                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.814403         812        6571"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df[df['reviewerID'] == 'A1HBTW5M7ZZ9PT']\n",
    "test = test[test['overall'] == 3]\n",
    "\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>productPublishedDate</th>\n",
       "      <th>asin</th>\n",
       "      <th>main_cat_All Beauty</th>\n",
       "      <th>main_cat_All Electronics</th>\n",
       "      <th>main_cat_Amazon Home</th>\n",
       "      <th>main_cat_Arts, Crafts &amp; Sewing</th>\n",
       "      <th>main_cat_Arts, Crafts &amp;amp; Sewing</th>\n",
       "      <th>main_cat_Automotive</th>\n",
       "      <th>main_cat_Baby</th>\n",
       "      <th>main_cat_Books</th>\n",
       "      <th>main_cat_Camera &amp; Photo</th>\n",
       "      <th>main_cat_Camera &amp;amp; Photo</th>\n",
       "      <th>main_cat_Car Electronics</th>\n",
       "      <th>main_cat_Cell Phones &amp; Accessories</th>\n",
       "      <th>main_cat_Cell Phones &amp;amp; Accessories</th>\n",
       "      <th>main_cat_Computers</th>\n",
       "      <th>main_cat_Gift Cards</th>\n",
       "      <th>main_cat_Grocery</th>\n",
       "      <th>main_cat_Health &amp; Personal Care</th>\n",
       "      <th>main_cat_Home Audio &amp; Theater</th>\n",
       "      <th>main_cat_Home Audio &amp;amp; Theater</th>\n",
       "      <th>main_cat_Industrial &amp; Scientific</th>\n",
       "      <th>main_cat_Industrial &amp;amp; Scientific</th>\n",
       "      <th>main_cat_Musical Instruments</th>\n",
       "      <th>main_cat_Office Products</th>\n",
       "      <th>main_cat_Pet Supplies</th>\n",
       "      <th>main_cat_Portable Audio &amp; Accessories</th>\n",
       "      <th>main_cat_Software</th>\n",
       "      <th>main_cat_Sports &amp; Outdoors</th>\n",
       "      <th>main_cat_Sports &amp;amp; Outdoors</th>\n",
       "      <th>main_cat_Tools &amp; Home Improvement</th>\n",
       "      <th>main_cat_Tools &amp;amp; Home Improvement</th>\n",
       "      <th>main_cat_Toys &amp; Games</th>\n",
       "      <th>main_cat_Toys &amp;amp; Games</th>\n",
       "      <th>main_cat_Video Games</th>\n",
       "      <th>dayDifferenceProduct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xclusive design classi</td>\n",
       "      <td>best abstract fiery floral design mouse pad cu...</td>\n",
       "      <td>luxladymousepad</td>\n",
       "      <td>material made best plastic manufacturing also ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>September 21, 1677</td>\n",
       "      <td>B00KH94VSG</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.059833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itten piano key mouse pad 8 x 8 x 25 made heav...</td>\n",
       "      <td>3drose llc 8 x 8 x 025 inch kitten piano key m...</td>\n",
       "      <td>3drose</td>\n",
       "      <td>dimension inch 8 w x 8 h x 025 matte finish so...</td>\n",
       "      <td>1</td>\n",
       "      <td>July 14, 2014</td>\n",
       "      <td>B00CX71JNU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.848318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                                              title            brand                                            feature  rank productPublishedDate        asin  main_cat_All Beauty  main_cat_All Electronics  main_cat_Amazon Home  main_cat_Arts, Crafts & Sewing  main_cat_Arts, Crafts &amp; Sewing  main_cat_Automotive  main_cat_Baby  main_cat_Books  main_cat_Camera & Photo  main_cat_Camera &amp; Photo  main_cat_Car Electronics  main_cat_Cell Phones & Accessories  main_cat_Cell Phones &amp; Accessories  main_cat_Computers  main_cat_Gift Cards  main_cat_Grocery  main_cat_Health & Personal Care  main_cat_Home Audio & Theater  main_cat_Home Audio &amp; Theater  main_cat_Industrial & Scientific  main_cat_Industrial &amp; Scientific  main_cat_Musical Instruments  main_cat_Office Products  main_cat_Pet Supplies  main_cat_Portable Audio & Accessories  main_cat_Software  main_cat_Sports & Outdoors  main_cat_Sports &amp; Outdoors  main_cat_Tools & Home Improvement  main_cat_Tools &amp; Home Improvement  main_cat_Toys & Games  main_cat_Toys &amp; Games  main_cat_Video Games  dayDifferenceProduct\n",
       "0                             xclusive design classi  best abstract fiery floral design mouse pad cu...  luxladymousepad  material made best plastic manufacturing also ...    -1   September 21, 1677  B00KH94VSG                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   1                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         0                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.059833\n",
       "1  itten piano key mouse pad 8 x 8 x 25 made heav...  3drose llc 8 x 8 x 025 inch kitten piano key m...           3drose  dimension inch 8 w x 8 h x 025 matte finish so...     1        July 14, 2014  B00CX71JNU                    0                         0                     0                               0                                   0                    0              0               0                        0                            0                         0                                   0                                       0                   0                    0                 0                                0                              0                                  0                                 0                                     0                             0                         1                      0                                      0                  0                           0                               0                                  0                                      0                      0                          0                     0              0.848318"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unreviewed_products_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
