{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRS (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from icecream import ic\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "utils.seed_everything(42)\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init and reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(233469, 47) (661471, 8)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/merged_data_processed.csv')\n",
    "unreviewed_products_df = pd.read_csv('data/unreviewed_products_processed.csv')\n",
    "products_df = pd.read_csv('data/products_sampled_processed.csv')\n",
    "reviews_df = pd.read_csv('data/reviews_sampled_processed.csv')\n",
    "\n",
    "print(products_df.shape, reviews_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "reviews_df.drop_duplicates(subset=['reviewerID', 'asin', 'reviewText', 'summary'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# join products and reviews datasets\n",
    "df = reviews_df.merge(products_df, on='asin', how='inner')\n",
    "\n",
    "unreviewed_products_df = products_df[~products_df['asin'].isin(reviews_df['asin'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of df: (661471, 54)\n",
      "Shape of unreviewed_products_df: (209585, 47)\n",
      "Shape of products_df: (233469, 47)\n",
      "Shape of reviews_df: (661471, 8)\n"
     ]
    }
   ],
   "source": [
    "print(f'Shape of df: {df.shape}')\n",
    "print(f'Shape of unreviewed_products_df: {unreviewed_products_df.shape}')\n",
    "print(f'Shape of products_df: {products_df.shape}')\n",
    "print(f'Shape of reviews_df: {reviews_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data preparation for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User and product id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ids = df['reviewerID'].values\n",
    "product_ids = df['asin'].values\n",
    "\n",
    "user_id_map = {uid: idx for idx, uid in enumerate(set(user_ids))}\n",
    "product_id_map = {pid: idx for idx, pid in enumerate(set(product_ids))}\n",
    "\n",
    "# Map user and item IDs to indices\n",
    "df['user_index'] = df['reviewerID'].map(user_id_map)\n",
    "df['item_index'] = df['asin'].map(product_id_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Embeddings (with Word2Vec or whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Create embeddings using Word2Vec\n",
    "def create_word2vec_embeddings(texts, embedding_dim):\n",
    "  # Tokenize the texts\n",
    "  tokenized_texts = [text.split() for text in texts]\n",
    "  \n",
    "  # Train Word2Vec model\n",
    "  model = Word2Vec(tokenized_texts, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "  \n",
    "  # Get the embeddings for each text\n",
    "  embeddings = []\n",
    "  for text in tokenized_texts:\n",
    "      embedding = np.mean([model.wv[word] for word in text if word in model.wv], axis=0)\n",
    "      embeddings.append(embedding)\n",
    "  \n",
    "  return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviewed_products = products_df[products_df['asin'].isin(df['asin'].unique())].drop_duplicates(subset=['asin'])\n",
    "df_reviewed_products['brand'] = df_reviewed_products['brand'].astype(str)\n",
    "df_reviewed_products['title'] = df_reviewed_products['title'].astype(str)\n",
    "df_reviewed_products['description'] = df_reviewed_products['description'].astype(str)\n",
    "\n",
    "df_reviewed_products.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([661471, 200]) torch.Size([661471, 200]) torch.Size([233469, 200]) torch.Size([233469, 200]) torch.Size([233469, 200]) torch.Size([233469, 200])\n"
     ]
    }
   ],
   "source": [
    "# Create embeddings for textual data\n",
    "text_embedding_dims = 200\n",
    "reviewTexts_embs = torch.tensor(create_word2vec_embeddings(reviews_df['reviewText'].astype(str), embedding_dim=text_embedding_dims))\n",
    "summary_embs = torch.tensor(create_word2vec_embeddings(reviews_df['summary'].astype(str), embedding_dim=text_embedding_dims))\n",
    "title_embs = torch.tensor(create_word2vec_embeddings(products_df['title'].astype(str), embedding_dim=text_embedding_dims))\n",
    "description_embs = torch.tensor(create_word2vec_embeddings(products_df['description'].astype(str), embedding_dim=text_embedding_dims))\n",
    "feature_embs = torch.tensor(create_word2vec_embeddings(products_df['feature'].astype(str), embedding_dim=text_embedding_dims))\n",
    "brand_embs = torch.tensor(create_word2vec_embeddings(products_df['brand'].astype(str), embedding_dim=text_embedding_dims))\n",
    "\n",
    "#load the embeddings  \n",
    "# reviewTexts_embs = torch.load('data/embeds/review_embeddings.pt')\n",
    "# summary_embs = torch.load('data/embeds/summary_embeddings.pt')\n",
    "# description_embs = torch.load('data/embeds/description_embeddings.pt')\n",
    "# title_embs = torch.load('data/embeds/title_embeddings.pt')\n",
    "# feature_embs = torch.load('data/embeds/feature_embeddings.pt')\n",
    "# brand_embs = torch.load('data/embeds/brand_embeddings.pt')\n",
    "\n",
    "print(reviewTexts_embs.shape, summary_embs.shape, title_embs.shape, description_embs.shape, feature_embs.shape, brand_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review (user) embeddings by taking the mean of the review-related embeddings\n",
    "reviews_text_embs = torch.mean(torch.stack([reviewTexts_embs, summary_embs]), dim=0)\n",
    "\n",
    "# item embeddings by taking the mean of the item-related embeddings\n",
    "products_text_embs = torch.mean(torch.stack([title_embs, description_embs, feature_embs, brand_embs]), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embeddings_map = {}\n",
    "for i, row in reviews_df.iterrows():\n",
    "    user_id = row['reviewerID']   \n",
    "    if user_id not in user_embeddings_map:\n",
    "        user_embeddings_map[user_id] = [reviews_text_embs[i]]\n",
    "    else:\n",
    "        user_embeddings_map[user_id].append(reviews_text_embs[i])\n",
    "\n",
    "for user_id, emb in user_embeddings_map.items():\n",
    "    user_tensors = user_embeddings_map[user_id]\n",
    "    user_embeddings_map[user_id] = torch.mean(torch.stack(user_tensors), dim=0)\n",
    "    \n",
    "    \n",
    "df['user_embs'] = df['reviewerID'].map(user_embeddings_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_product_embeddings = {}\n",
    "for i, row in df_reviewed_products.iterrows():\n",
    "    product_id = row['asin']\n",
    "    all_product_embeddings[product_id] = products_text_embs[i]\n",
    "\n",
    "\n",
    "reviewed_products_embeddings_map = {}\n",
    "for i, row in df_reviewed_products.iterrows():\n",
    "    product_id = row['asin']\n",
    "    reviewed_products_embeddings_map[product_id] = all_product_embeddings[product_id]\n",
    "    \n",
    "df['product_embs'] = df['asin'].map(reviewed_products_embeddings_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DataLoaders for the Pytorch-based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split_colab(df, test_size=0.2):\n",
    "    \"\"\" \n",
    "    Split the dataframe into training and test sets,\n",
    "    by taking a percentage of the review from each user     \n",
    "    \"\"\"\n",
    "    train_set, test_set = [], []\n",
    "\n",
    "    for _, group in df.groupby('reviewerID'):\n",
    "        n = group.shape[0]\n",
    "        test_n = int(n * test_size)\n",
    "        test_indices = np.random.choice(group.index, size=test_n, replace=False)\n",
    "        test_set.append(group.loc[test_indices])\n",
    "        train_set.append(group.drop(test_indices))\n",
    "        \n",
    "    train_set = pd.concat(train_set)\n",
    "    test_set = pd.concat(test_set)\n",
    "    \n",
    "    return train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "import numpy as np\n",
    "\n",
    "# class for the dataset\n",
    "class AmazonReviewDataset(Dataset):\n",
    "    def __init__(self, user_ids, product_ids, ratings, users_text_data, products_text_data):\n",
    "        self.user_ids = user_ids\n",
    "        self.product_ids = product_ids\n",
    "        self.ratings = ratings\n",
    "        self.users_text_data = users_text_data\n",
    "        self.products_text_data = products_text_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        item_id = self.product_ids[index]\n",
    "        rating = self.ratings[index]\n",
    "        users_text_data = self.users_text_data[index]\n",
    "        products_text_data = self.products_text_data[index]\n",
    "        \n",
    "        return user_id, item_id, rating, users_text_data, products_text_data\n",
    "\n",
    "# Split the data into train and test sets\n",
    "# train_data, val_data = train_test_split_colab(df, test_size=0.2)\n",
    "train_data, val_data = train_test_split_colab(df, test_size=0.2)\n",
    "\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = AmazonReviewDataset(\n",
    "    train_data['user_index'].values,\n",
    "    train_data['item_index'].values,\n",
    "    train_data['overall'].values,\n",
    "    train_data['user_embs'].values,\n",
    "    train_data['product_embs'].values\n",
    "\n",
    ")\n",
    "\n",
    "test_dataset = AmazonReviewDataset(\n",
    "    val_data['user_index'].values,\n",
    "    val_data['item_index'].values,\n",
    "    val_data['overall'].values,\n",
    "    val_data['user_embs'].values,\n",
    "    train_data['product_embs'].values\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model test with SVD from scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick performance check of SVD by using scikit-surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9300\n",
      "RMSE: 0.9356\n",
      "RMSE: 0.9327\n",
      "RMSE: 0.9313\n",
      "RMSE: 0.9323\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly, Dataset, SVD, Reader, accuracy, Trainset\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_test = Dataset.load_from_df(df[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data_test, test_size=0.25)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data_test):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 'A1HBTW5M7ZZ9PT'\n",
    "test_user = reviews_df[reviews_df['reviewerID'] == user_id]\n",
    "item_id = 'B00006IEI7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: A1HBTW5M7ZZ9PT item: B00006IEI7 r_ui = 5.00   est = 4.43   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(user_id, item_id, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3930242501.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[18], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    class NeuMF(nn.Module):class NeuMF(nn.Module):\u001b[0m\n\u001b[0m                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from time import time\n",
    "from evaluate import evaluate_model\n",
    "from Dataset import Dataset\n",
    "\n",
    "class NeuMF(nn.Module):class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mf_dim, layers, reg_layers, reg_mf):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mf_dim = mf_dim\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.reg_layers = reg_layers\n",
    "        self.reg_mf = reg_mf\n",
    "        \n",
    "        self.mf_embedding_user = nn.Embedding(num_users, mf_dim)\n",
    "        self.mf_embedding_item = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        self.mlp_embedding_user = nn.Embedding(num_users, layers[0]//2)\n",
    "        self.mlp_embedding_item = nn.Embedding(num_items, layers[0]//2)\n",
    "        \n",
    "        self.mlp_layers = nn.ModuleList()\n",
    "        for i in range(1, self.num_layers):\n",
    "            self.mlp_layers.append(nn.Linear(layers[i-1], layers[i]))\n",
    "        \n",
    "        self.prediction_layer = nn.Linear(layers[-1] + mf_dim, 1)\n",
    "        \n",
    "    def forward(self, user_input, item_input, user_text_embeddings, item_text_embeddings):\n",
    "        mf_user_latent = self.mf_embedding_user(user_input)\n",
    "        mf_item_latent = self.mf_embedding_item(item_input)\n",
    "        mf_vector = mf_user_latent * mf_item_latent\n",
    "        \n",
    "        mlp_user_latent = self.mlp_embedding_user(user_input)\n",
    "        mlp_item_latent = self.mlp_embedding_item(item_input)\n",
    "        mlp_vector = torch.cat([mlp_user_latent, mlp_item_latent, user_text_embeddings, item_text_embeddings], dim=-1)\n",
    "        \n",
    "        for i in range(1, self.num_layers):\n",
    "            mlp_vector = self.mlp_layers[i-1](mlp_vector)\n",
    "            mlp_vector = nn.ReLU()(mlp_vector)\n",
    "        \n",
    "        predict_vector = torch.cat([mf_vector, mlp_vector], dim=-1)\n",
    "        prediction = self.prediction_layer(predict_vector)\n",
    "        return prediction.view(-1)\n",
    "    def __init__(self, num_users, num_items, mf_dim, layers, reg_layers, reg_mf):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mf_dim = mf_dim\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.reg_layers = reg_layers\n",
    "        self.reg_mf = reg_mf\n",
    "        \n",
    "        self.mf_embedding_user = nn.Embedding(num_users, mf_dim)\n",
    "        self.mf_embedding_item = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        self.mlp_embedding_user = nn.Embedding(num_users, layers[0]//2)\n",
    "        self.mlp_embedding_item = nn.Embedding(num_items, layers[0]//2)\n",
    "        \n",
    "        self.mlp_layers = nn.ModuleList()\n",
    "        for i in range(1, self.num_layers):\n",
    "            self.mlp_layers.append(nn.Linear(layers[i-1], layers[i]))\n",
    "        \n",
    "        self.prediction_layer = nn.Linear(layers[-1] + mf_dim, 1)\n",
    "        \n",
    "    def forward(self, user_input, item_input, user_text_embeddings, item_text_embeddings):\n",
    "        mf_user_latent = self.mf_embedding_user(user_input)\n",
    "        mf_item_latent = self.mf_embedding_item(item_input)\n",
    "        mf_vector = mf_user_latent * mf_item_latent\n",
    "        \n",
    "        mlp_user_latent = self.mlp_embedding_user(user_input)\n",
    "        mlp_item_latent = self.mlp_embedding_item(item_input)\n",
    "        mlp_vector = torch.cat([mlp_user_latent, mlp_item_latent, user_text_embeddings, item_text_embeddings], dim=-1)\n",
    "        \n",
    "        for i in range(1, self.num_layers):\n",
    "            mlp_vector = self.mlp_layers[i-1](mlp_vector)\n",
    "            mlp_vector = nn.ReLU()(mlp_vector)\n",
    "        \n",
    "        predict_vector = torch.cat([mf_vector, mlp_vector], dim=-1)\n",
    "        prediction = self.prediction_layer(predict_vector)\n",
    "        return prediction.view(-1)\n",
    "    \n",
    "def get_train_instances(train, num_negatives):\n",
    "    user_input, item_input, labels = [], [], []\n",
    "    num_users = train.shape[0]\n",
    "    for (u, i) in train.keys():\n",
    "        # positive instance\n",
    "        user_input.append(u)\n",
    "        item_input.append(i)\n",
    "        labels.append(1)\n",
    "        # negative instances\n",
    "        for _ in range(num_negatives):\n",
    "            j = np.random.randint(num_items)\n",
    "            while train.has_key((u, j)):\n",
    "                j = np.random.randint(num_items)\n",
    "            user_input.append(u)\n",
    "            item_input.append(j)\n",
    "            labels.append(0)\n",
    "    return user_input, item_input, labels\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    args = parse_args()\n",
    "    num_epochs = args.epochs\n",
    "    batch_size = args.batch_size\n",
    "    mf_dim = args.num_factors\n",
    "    layers = eval(args.layers)\n",
    "    reg_mf = args.reg_mf\n",
    "    reg_layers = eval(args.reg_layers)\n",
    "    num_negatives = args.num_neg\n",
    "    learning_rate = args.lr\n",
    "    learner = args.learner\n",
    "    verbose = args.verbose\n",
    "    \n",
    "    topK = 10\n",
    "    print(\"NeuMF arguments: %s \" %(args))\n",
    "    model_out_file = 'Pretrain/%s_NeuMF_%d_%s_%d.pt' %(args.dataset, mf_dim, args.layers, time())\n",
    "    \n",
    "    # Loading data\n",
    "    t1 = time()\n",
    "    dataset = Dataset(args.path + args.dataset)\n",
    "    train, testRatings, testNegatives = dataset.trainMatrix, dataset.testRatings, dataset.testNegatives\n",
    "    num_users, num_items = train.shape\n",
    "    print(\"Load data done [%.1f s]. #user=%d, #item=%d, #train=%d, #test=%d\" \n",
    "          %(time()-t1, num_users, num_items, train.nnz, len(testRatings)))\n",
    "    \n",
    "    # Build model\n",
    "    model = NeuMF(num_users, num_items, mf_dim, layers, reg_layers, reg_mf)\n",
    "    if learner.lower() == \"adagrad\": \n",
    "        optimizer = optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "    elif learner.lower() == \"rmsprop\":\n",
    "        optimizer = optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "    elif learner.lower() == \"adam\":\n",
    "        optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    else:\n",
    "        optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    \n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    # Check Init performance\n",
    "    (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK)\n",
    "    hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "    print('Init: HR = %.4f, NDCG = %.4f' % (hr, ndcg))\n",
    "    best_hr, best_ndcg, best_iter = hr, ndcg, -1\n",
    "    if args.out > 0:\n",
    "        torch.save(model.state_dict(), model_out_file)\n",
    "    \n",
    "    # Training model\n",
    "    for epoch in range(num_epochs):\n",
    "        t1 = time()\n",
    "        # Generate training instances\n",
    "        user_input, item_input, labels = get_train_instances(train, num_negatives)\n",
    "        \n",
    "        # Training\n",
    "        model.train()\n",
    "        for i in range(0, len(user_input), batch_size):\n",
    "            batch_user_input = torch.LongTensor(user_input[i:i+batch_size])\n",
    "            batch_item_input = torch.LongTensor(item_input[i:i+batch_size])\n",
    "            batch_user_text_embeddings = torch.FloatTensor(dataset.user_text_embeddings[user_input[i:i+batch_size]])\n",
    "            batch_item_text_embeddings = torch.FloatTensor(dataset.item_text_embeddings[item_input[i:i+batch_size]])\n",
    "            batch_labels = torch.FloatTensor(labels[i:i+batch_size])\n",
    "            optimizer.zero_grad()\n",
    "            predictions = model(batch_user_input, batch_item_input, batch_user_text_embeddings, batch_item_text_embeddings)\n",
    "            loss = criterion(predictions, batch_labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        t2 = time()\n",
    "        \n",
    "        # Evaluation\n",
    "        if epoch % verbose == 0:\n",
    "            model.eval()\n",
    "            (hits, ndcgs) = evaluate_model(model, testRatings, testNegatives, topK)\n",
    "            hr, ndcg = np.array(hits).mean(), np.array(ndcgs).mean()\n",
    "            print('Iteration %d [%.1f s]: HR = %.4f, NDCG = %.4f, loss = %.4f [%.1f s]' \n",
    "                  % (epoch, t2-t1, hr, ndcg, loss.item(), time()-t2))\n",
    "            if hr > best_hr:\n",
    "                best_hr, best_ndcg, best_iter = hr, ndcg, epoch\n",
    "                if args.out > 0:\n",
    "                    torch.save(model.state_dict(), model_out_file)\n",
    "    \n",
    "    print(\"End. Best Iteration %d:  HR = %.4f, NDCG = %.4f. \" %(best_iter, best_hr, best_ndcg))\n",
    "    if args.out > 0:\n",
    "        print(\"The best NeuMF model is saved to %s\" %(model_out_file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class NeuMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, mf_dim, layers, reg_layers, reg_mf):\n",
    "        super(NeuMF, self).__init__()\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.mf_dim = mf_dim\n",
    "        self.layers = layers\n",
    "        self.num_layers = len(layers)\n",
    "        self.reg_layers = reg_layers\n",
    "        self.reg_mf = reg_mf\n",
    "        \n",
    "        self.mf_embedding_user = nn.Embedding(num_users, mf_dim)\n",
    "        self.mf_embedding_item = nn.Embedding(num_items, mf_dim)\n",
    "        \n",
    "        self.mlp_embedding_user = nn.Embedding(num_users, layers[0]//2)\n",
    "        self.mlp_embedding_item = nn.Embedding(num_items, layers[0]//2)\n",
    "        \n",
    "        self.mlp_layers = nn.ModuleList()\n",
    "        for i in range(1, self.num_layers):\n",
    "            self.mlp_layers.append(nn.Linear(layers[i-1], layers[i]))\n",
    "        \n",
    "        self.prediction_layer = nn.Linear(layers[-1] + mf_dim, 1)\n",
    "        \n",
    "    def forward(self, user_input, item_input, user_text_embeddings, item_text_embeddings):\n",
    "        mf_user_latent = self.mf_embedding_user(user_input)\n",
    "        mf_item_latent = self.mf_embedding_item(item_input)\n",
    "        mf_vector = mf_user_latent * mf_item_latent\n",
    "        \n",
    "        mlp_user_latent = self.mlp_embedding_user(user_input)\n",
    "        mlp_item_latent = self.mlp_embedding_item(item_input)\n",
    "        mlp_vector = torch.cat([mlp_user_latent, mlp_item_latent, user_text_embeddings, item_text_embeddings], dim=-1)\n",
    "        \n",
    "        for i in range(1, self.num_layers):\n",
    "            mlp_vector = self.mlp_layers[i-1](mlp_vector)\n",
    "            mlp_vector = nn.ReLU()(mlp_vector)\n",
    "        \n",
    "        predict_vector = torch.cat([mf_vector, mlp_vector], dim=-1)\n",
    "        prediction = self.prediction_layer(predict_vector)\n",
    "        return prediction.view(-1)\n",
    "\n",
    "class NCF(nn.Module):\n",
    "  def __init__(self, n_users, n_items, emb_dim, text_user_dim, text_item_dim, dropout_rate=0.2) -> None:\n",
    "    super(NCF, self).__init__()\n",
    "    self.min_rating = 1\n",
    "    self.max_rating = 5\n",
    "    self.n_users = n_users\n",
    "    self.n_items = n_items\n",
    "    self.emb_dim = emb_dim\n",
    "    \n",
    "    # GMF embeddings\n",
    "    self.user_embedding_gmf = nn.Embedding(n_users, emb_dim)\n",
    "    self.item_embedding_gmf = nn.Embedding(n_items, emb_dim)\n",
    "    \n",
    "    # MLP embeddings\n",
    "    self.user_embedding_mlp = nn.Embedding(n_users, 2048 // 2)\n",
    "    self.item_embedding_mlp = nn.Embedding(n_items, 2048 // 2)\n",
    "    \n",
    "    # text embeddings\n",
    "    self.user_text_layer = nn.Linear(text_user_dim, text_user_dim)\n",
    "    self.item_text_layer = nn.Linear(text_item_dim, text_item_dim)\n",
    "    \n",
    "    # MLP layers\n",
    "    self.fc_layers = nn.Sequential(\n",
    "      nn.Linear(800, 1024),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(p=dropout_rate),\n",
    "      nn.BatchNorm1d(1024),\n",
    "      \n",
    "      nn.Linear(1024, 512),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(p=dropout_rate),\n",
    "      nn.BatchNorm1d(512),\n",
    "      \n",
    "      nn.Linear(512, 256),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(p=dropout_rate),\n",
    "      nn.BatchNorm1d(256),\n",
    "      \n",
    "      nn.Linear(256, 128),\n",
    "      nn.ReLU(),\n",
    "      nn.Dropout(p=dropout_rate),\n",
    "      nn.BatchNorm1d(128),\n",
    "      \n",
    "      nn.Linear(128, 64),\n",
    "      nn.ReLU()\n",
    "    )\n",
    "    \n",
    "    # Output layertorch.mul(user_gmf, item_gmf)\n",
    "    self.output_layer = nn.Linear(emb_dim + 64, 1)\n",
    "    \n",
    "    # Initialize weights\n",
    "    self._init_embs_weight_()\n",
    "        \n",
    "  def _init_embs_weight_(self):\n",
    "    nn.init.normal_(self.user_embedding_gmf.weight, std=0.01)\n",
    "    nn.init.normal_(self.item_embedding_gmf.weight, std=0.01)\n",
    "    nn.init.normal_(self.user_embedding_mlp.weight, std=0.01)\n",
    "    nn.init.normal_(self.item_embedding_mlp.weight, std=0.01)\n",
    "    \n",
    "  def forward(self, user_ids, item_ids, user_texts, item_texts):\n",
    "    # GMF part\n",
    "    user_gmf = self.user_embedding_gmf(user_ids)\n",
    "    item_gmf = self.item_embedding_gmf(item_ids)\n",
    "    gmf_output = user_gmf * item_gmf\n",
    "    \n",
    "    # MLP part\n",
    "    user_mlp = self.user_embedding_mlp(user_ids)\n",
    "    item_mlp = self.item_embedding_mlp(item_ids)\n",
    "    user_text_mlp = self.user_text_layer(user_texts)\n",
    "    item_text_mlp = self.item_text_layer(item_texts)\n",
    "    mlp_input = torch.cat([user_mlp, item_mlp, user_text_mlp, item_text_mlp], dim=1)\n",
    "    mlp_output = self.fc_layers(mlp_input)\n",
    "    \n",
    "    # Concatenate GMF and MLP output\n",
    "    output = self.output_layer(torch.cat([gmf_output, mlp_output], dim=1))\n",
    "    output = output * (self.max_rating - self.min_rating) + self.min_rating\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating - related functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NCF model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def __init__(self, eps=1e-6):\n",
    "        super().__init__()\n",
    "        self.mse = nn.MSELoss()\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self,yhat,y):\n",
    "        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n",
    "        return loss\n",
    "\n",
    "def train_model(model: NCF, train_data: AmazonReviewDataset, val_data: AmazonReviewDataset, loss_func, optimizer, device, num_epochs):\n",
    "    train_loss_history = []\n",
    "    valid_loss_history = []\n",
    "    precision_at_k_history = []\n",
    "    \n",
    "    model.to(device)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss_sum = 0\n",
    "\n",
    "        # For each batch\n",
    "        for user_ids, item_ids, rating, u_text_embeds, p_text_embeds in tqdm(train_data, desc='Training...'):\n",
    "            user_ids, item_ids, rating = user_ids.to(device), item_ids.to(device), rating.to(device)\n",
    "            u_text_embeds, p_text_embeds = u_text_embeds.to(device), p_text_embeds.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, item_ids, u_text_embeds, p_text_embeds)\n",
    "            loss = loss_func(outputs.squeeze(), rating.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += loss.item()\n",
    "\n",
    "        model.eval()\n",
    "        scheduler.step()\n",
    "        val_loss, _, _ = predict_and_evaluate(model, val_data, loss_func, device)\n",
    "                \n",
    "        # for both training and validation, the actual train loss\n",
    "        # is the average loss over the entire dataset (the multiple batches)\n",
    "        train_loss = np.sqrt(train_loss_sum / len(train_data))\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(val_loss)\n",
    "        \n",
    "        # precision@k\n",
    "        p_at_k = precision_at_k(model, val_data, 10)\n",
    "        precision_at_k_history.append(p_at_k)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}: train loss = {train_loss:.4f}, val loss = {val_loss:.4f}, HR@k = {p_at_k:.4f}')\n",
    "    \n",
    "    return train_loss_history, valid_loss_history\n",
    "        \n",
    "# Evaluate the NCF model\n",
    "def predict_and_evaluate(model, data, loss_func, device):\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    loss_sum = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, rating, u_text_embeds, p_text_embeds in tqdm(data, desc='Evaluating...'):\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            u_text_embeds = u_text_embeds.to(device)\n",
    "            p_text_embeds = p_text_embeds.to(device)\n",
    "            \n",
    "            outputs = model(user_ids, item_ids, u_text_embeds, p_text_embeds)\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            true_ratings.extend(rating.tolist())\n",
    "            \n",
    "            loss_sum += loss_func(outputs.squeeze(), rating.float()).item()\n",
    "\n",
    "    rmse = np.sqrt(loss_sum / len(data))\n",
    "    mse = mean_squared_error(true_ratings, predictions)\n",
    "    mae = mean_absolute_error(true_ratings, predictions)\n",
    "    return rmse, mse, mae\n",
    "  \n",
    "def precision_at_k(model, test_dataset, k):\n",
    "    model.eval()\n",
    "    \n",
    "    precision_sum = 0.0\n",
    "    total_users = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for user_ids, item_ids, rating, u_text_embeds, p_text_embeds in test_dataset:\n",
    "            # Get the predicted scores for all items\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            u_text_embeds = u_text_embeds.to(device)\n",
    "            p_text_embeds = p_text_embeds.to(device)\n",
    "            \n",
    "            scores = model(user_ids, item_ids, u_text_embeds, p_text_embeds)\n",
    "            \n",
    "            # Get the indices of the top K items\n",
    "            _, indices = torch.topk(scores.squeeze(), k)\n",
    "            \n",
    "            # Check how many of the top K items are relevant\n",
    "            relevant_count = 0\n",
    "            for item in item_ids:\n",
    "                if item in indices:\n",
    "                    relevant_count += 1\n",
    "            \n",
    "            # Calculate Precision@K for the current user\n",
    "            precision = relevant_count / k\n",
    "            \n",
    "            precision_sum += precision\n",
    "            total_users += 1\n",
    "    \n",
    "    # Calculate average Precision@K across all users\n",
    "    average_precision = precision_sum / total_users\n",
    "    \n",
    "    return average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss criterion: RMSE\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training...:   0%|          | 0/278 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2048x200 and 768x768)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss criterion: RMSE\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m train_loss_history, val_loss_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 33\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_data, val_data, loss_func, optimizer, device, num_epochs)\u001b[0m\n\u001b[1;32m     30\u001b[0m u_text_embeds, p_text_embeds \u001b[38;5;241m=\u001b[39m u_text_embeds\u001b[38;5;241m.\u001b[39mto(device), p_text_embeds\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     32\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 33\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mitem_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu_text_embeds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_text_embeds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(outputs\u001b[38;5;241m.\u001b[39msqueeze(), rating\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     35\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[19], line 111\u001b[0m, in \u001b[0;36mNCF.forward\u001b[0;34m(self, user_ids, item_ids, user_texts, item_texts)\u001b[0m\n\u001b[1;32m    109\u001b[0m user_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser_embedding_mlp(user_ids)\n\u001b[1;32m    110\u001b[0m item_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_embedding_mlp(item_ids)\n\u001b[0;32m--> 111\u001b[0m user_text_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muser_text_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_texts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m item_text_mlp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem_text_layer(item_texts)\n\u001b[1;32m    113\u001b[0m mlp_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([user_mlp, item_mlp, user_text_mlp, item_text_mlp], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2048x200 and 768x768)"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2048, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=2048, shuffle=False)\n",
    "\n",
    "# Create the NCF model\n",
    "num_users = len(user_id_map)\n",
    "num_items = len(product_id_map)\n",
    "emb_dim = 768\n",
    "droput_rate_fc = 0\n",
    "text_embedding_dims = [emb.shape[1] for emb in [reviews_text_embs, products_text_embs]]\n",
    "\n",
    "model = NCF(\n",
    "  num_users, num_items, emb_dim, 768, 768, droput_rate_fc).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_func = RMSELoss()\n",
    "# criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "print('Loss criterion: RMSE\\n')\n",
    "train_loss_history, val_loss_history = train_model(model, train_loader, test_loader, loss_func, optimizer, device, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_accuracy(train_acc_history, val_acc_history, loss_name='RMSE'):\n",
    "  df = pd.DataFrame({'Epoch': range(1, len(train_acc_history)+1),\n",
    "             'Train Accuracy': train_acc_history, \n",
    "             'Validation Accuracy': val_acc_history})\n",
    "\n",
    "  plt.figure(figsize=(10, 6))\n",
    "  sns.lineplot(data=df, x='Epoch', y='Train Accuracy', label=f'Train loss ({loss_name})')\n",
    "  sns.lineplot(data=df, x='Epoch', y='Validation Accuracy', label=f'Validation loss ({loss_name})')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel(loss_name)\n",
    "  plt.title(f'Training and Validation loss {loss_name}')\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "  \n",
    "plot_accuracy(train_loss_history, val_loss_history, 'RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model test with single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_mapping' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m         score \u001b[38;5;241m=\u001b[39m model(user_tensor, item_tensor)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m score\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted rating for user \u001b[39m\u001b[38;5;132;01m{\u001b[39;00muser_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and item \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredict_score(user_id,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB0006HXE1E\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39mmodel,\u001b[38;5;250m \u001b[39m\u001b[43muser_mapping\u001b[49m,\u001b[38;5;250m \u001b[39mproduct_mapping,\u001b[38;5;250m \u001b[39mdevice)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# print(f'Actual rating: {user_product_matrix.loc[user_id, item_id]}')\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_mapping' is not defined"
     ]
    }
   ],
   "source": [
    "def predict_score(user_id, item_id, model, user_mapping, item_mapping, device):\n",
    "    # Convert user ID and item ID to their corresponding indices\n",
    "    user_index = user_mapping[user_id]\n",
    "    item_index = item_mapping[item_id]\n",
    "\n",
    "    # Convert indices to tensors\n",
    "    user_tensor = torch.tensor([user_index], dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor([item_index], dtype=torch.long).to(device)\n",
    "\n",
    "    # Get the predicted score from the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        score = model(user_tensor, item_tensor).item()\n",
    "\n",
    "    return score\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_score(user_id, 'B0006HXE1E', model, user_mapping, product_mapping, device)}')\n",
    "# print(f'Actual rating: {user_product_matrix.loc[user_id, item_id]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unreviewed_products_df.head(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
