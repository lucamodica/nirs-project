{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRS (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import icecream as ic\n",
    "\n",
    "utils.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('data/reviews_sampled_processed.csv')\n",
    "products_df = pd.read_csv('data/products_sampled_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "products_df = products_df.drop_duplicates(subset='asin', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews df shape: (45562, 7)\n",
      "Products df shape: (17766, 8)\n"
     ]
    }
   ],
   "source": [
    "utils.print_shapes(reviews_df, products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 17766\n",
      "Number of unique users: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique products: {products_df[\"asin\"].nunique()}')\n",
    "print(f'Number of unique users: {reviews_df[\"reviewerID\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 02, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>0310818621</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>absolutely love organizer never one figured wa...</td>\n",
       "      <td>super good deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>March 21, 2014</td>\n",
       "      <td>A2F0F4NB6BLGVX</td>\n",
       "      <td>0310823706</td>\n",
       "      <td>Lee</td>\n",
       "      <td>good bible carrier large print bible afraid wo...</td>\n",
       "      <td>leatherlook bible carrier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 02, 2017</td>\n",
       "      <td>A23BRQWL8LNB37</td>\n",
       "      <td>0439499887</td>\n",
       "      <td>David</td>\n",
       "      <td>kid love peppa reading say</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall      reviewTime      reviewerID        asin reviewerName                                         reviewText                    summary\n",
       "0      5.0   June 02, 2015  A1HBTW5M7ZZ9PT  0310818621        FTLOE  absolutely love organizer never one figured wa...            super good deal\n",
       "1      5.0  March 21, 2014  A2F0F4NB6BLGVX  0310823706          Lee  good bible carrier large print bible afraid wo...  leatherlook bible carrier\n",
       "2      5.0   June 02, 2017  A23BRQWL8LNB37  0439499887        David                         kid love peppa reading say                  five star"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>productPublishedDate</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rotect rfid card skimsafe card holder made rig...</td>\n",
       "      <td>Black RFID Blocking ID Badge Holder (Holds 2 C...</td>\n",
       "      <td>Specialist ID</td>\n",
       "      <td>rfid blocking 2 card holder fips 201 approved ...</td>\n",
       "      <td>43</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>October 14, 2011</td>\n",
       "      <td>B005VSY1VK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itten piano key mouse pad 8 x 8 x 25 made heav...</td>\n",
       "      <td>3dRose LLC 8 x 8 x 0.25 Inches Kitten on Piano...</td>\n",
       "      <td>3dRose</td>\n",
       "      <td>dimension inch 8 w x 8 h x 025 matte finish so...</td>\n",
       "      <td>1</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>July 14, 2014</td>\n",
       "      <td>B00CX71JNU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ivo next favorite pen ultra gel stick vibrant ...</td>\n",
       "      <td>Vivo Ultra Gel Stick Pens, 0.7mm Fine Tip, Bla...</td>\n",
       "      <td>VIVO</td>\n",
       "      <td>ultra smooth gel ink vivid black amp color ful...</td>\n",
       "      <td>1</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>April 30, 2009</td>\n",
       "      <td>B002CO43BO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                                              title          brand                                            feature  rank         main_cat productPublishedDate        asin\n",
       "0  rotect rfid card skimsafe card holder made rig...  Black RFID Blocking ID Badge Holder (Holds 2 C...  Specialist ID  rfid blocking 2 card holder fips 201 approved ...    43  Office Products     October 14, 2011  B005VSY1VK\n",
       "1  itten piano key mouse pad 8 x 8 x 25 made heav...  3dRose LLC 8 x 8 x 0.25 Inches Kitten on Piano...         3dRose  dimension inch 8 w x 8 h x 025 matte finish so...     1  Office Products        July 14, 2014  B00CX71JNU\n",
       "2  ivo next favorite pen ultra gel stick vibrant ...  Vivo Ultra Gel Stick Pens, 0.7mm Fine Tip, Bla...           VIVO  ultra smooth gel ink vivid black amp color ful...     1  Office Products       April 30, 2009  B002CO43BO"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>productPublishedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>0136039847</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>earson myhistorylab online access code america...</td>\n",
       "      <td>Pearson MyHistoryLab Online Access Code for Am...</td>\n",
       "      <td>Pearson MyHistoryLab</td>\n",
       "      <td>pearson myhistorylab online access code americ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>June 21, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 02, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>0310818621</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>absolutely love organizer never one figured wa...</td>\n",
       "      <td>super good deal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>March 21, 2014</td>\n",
       "      <td>A2F0F4NB6BLGVX</td>\n",
       "      <td>0310823706</td>\n",
       "      <td>Lee</td>\n",
       "      <td>good bible carrier large print bible afraid wo...</td>\n",
       "      <td>leatherlook bible carrier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall      reviewTime      reviewerID        asin reviewerName                                         reviewText                    summary                                        description                                              title                 brand                                            feature  rank         main_cat productPublishedDate\n",
       "0      0.0             NaN         Unknown  0136039847          NaN                                                NaN                        NaN  earson myhistorylab online access code america...  Pearson MyHistoryLab Online Access Code for Am...  Pearson MyHistoryLab  pearson myhistorylab online access code americ...   1.0  Office Products        June 21, 2012\n",
       "1      5.0   June 02, 2015  A1HBTW5M7ZZ9PT  0310818621        FTLOE  absolutely love organizer never one figured wa...            super good deal                                                NaN                                                NaN                   NaN                                                NaN   NaN              NaN                  NaN\n",
       "2      5.0  March 21, 2014  A2F0F4NB6BLGVX  0310823706          Lee  good bible carrier large print bible afraid wo...  leatherlook bible carrier                                                NaN                                                NaN                   NaN                                                NaN   NaN              NaN                  NaN"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the datasets\n",
    "df = pd.merge(reviews_df, products_df, on='asin', how='outer')\n",
    "\n",
    "# Fill NaN values with appropriate values\n",
    "df['overall'] = df['overall'].fillna(0)  # Fill missing ratings with 0\n",
    "df['reviewerID'] = df['reviewerID'].fillna('Unknown')  # Fill missing user IDs with 'Unknown'\n",
    "df['asin'] = df['asin'].fillna('Unknown')  # Fill missing product IDs with 'Unknown'\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data preparation for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed (SVD) from user-matrix pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pivot table with the user-item interactions (reviews)\n",
    "user_product_matrix = pd.pivot_table(df, values='overall', index='reviewerID', columns='asin', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1001, 29694)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of users and items\n",
    "user_product_matrix.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_embeddings(user_item_matrix: pd.DataFrame, embedding_length):\n",
    "    \"\"\"\n",
    "    Apply SVD to the user-item matrix to obtain user and item embeddings.\n",
    "    U = m x r orthogonal left singular matrix, which represents the relationship between users and latent factors\n",
    "    S = r x r diagonal matrix, which describes the strength of each latent factor\n",
    "    V = r x n diagonal right singular matrix, which indicates the similarity between items and latent factors\n",
    "    \n",
    "    :param user_item_matrix: user-item matrix\n",
    "    :param embedding_length: number of latent factors, which is the dimensionality of the reduced space\n",
    "    \"\"\"\n",
    "    from scipy.sparse.linalg import svds\n",
    "    \n",
    "    # transpose the matrix to obtain the item-user matrix\n",
    "    # (this due to the large number of items compared to users)\n",
    "    matrix = user_item_matrix.values\n",
    "\n",
    "    U, Sigma, VT = svds(matrix, k=embedding_length)\n",
    "    user_embed_df = pd.DataFrame(U, index = user_item_matrix.index)\n",
    "    VT_T = np.transpose(VT)\n",
    "    item_embed_df = pd.DataFrame(VT_T, index=user_item_matrix.columns)\n",
    "    \n",
    "    return user_embed_df, item_embed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed_df, item_embed_df = SVD_embeddings(user_product_matrix, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews df shape: (1001, 800)\n",
      "Products df shape: (29694, 800)\n"
     ]
    }
   ],
   "source": [
    "utils.print_shapes(user_embed_df, item_embed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A100WO06OQR8BQ and item B000034DLQ: 0.033576172950954386\n"
     ]
    }
   ],
   "source": [
    "# predictions with the the obrained SVD embeddings\n",
    "def predict_ratings(user_embed_df: pd.DataFrame, item_embed_df: pd.DataFrame, user_id: str, item_id: str):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given user and item.\n",
    "    \n",
    "    :param user_embed_df: user embeddings\n",
    "    :param item_embed_df: item embeddings\n",
    "    :param user_id: user id\n",
    "    :param item_id: item id\n",
    "    \"\"\"\n",
    "    user_embedding = user_embed_df.loc[user_id]\n",
    "    item_embedding = item_embed_df.loc[item_id]\n",
    "    \n",
    "    \n",
    "    rating = np.dot(user_embedding, item_embedding)\n",
    "    return rating\n",
    "\n",
    "# example of prediction with a an item rated by a user\n",
    "user_id = user_product_matrix.index[0]\n",
    "\n",
    "# take the first product id rated by \"user_id\"\n",
    "# (thus an element that is not 0 in the user-product matrix)\n",
    "item_id = user_product_matrix.columns[user_product_matrix.loc[user_id] != 0].values[0]\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_ratings(user_embed_df, item_embed_df, user_id, item_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the predictions are consistent with the actual ratings\n",
    "actual_rating = user_product_matrix.loc[user_id, item_id]\n",
    "\n",
    "actual_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.15312314e-18,  1.56299148e-03,  1.91088821e-03, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-8.95960646e-18,  8.71139059e-04,  8.91887448e-04, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-2.30808540e-18,  8.34657369e-04, -3.89877065e-03, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-5.98872306e-18,  1.02680846e-04,  1.42300246e-03, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-1.29047853e-17, -1.63814272e-03,  3.18799017e-04, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 9.56213196e-32,  7.09309961e-17,  4.34223589e-17, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_embed_df, item_embed_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model test with SVD from scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick performance check of SVD by using scikit-surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8372\n",
      "RMSE: 0.8370\n",
      "RMSE: 0.8243\n",
      "RMSE: 0.8329\n",
      "RMSE: 0.8385\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly, Dataset, SVD, Reader, accuracy, Trainset\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_test = Dataset.load_from_df(df[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data_test, test_size=0.25)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data_test):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 02, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>0310818621</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>absolutely love organizer never one figured wa...</td>\n",
       "      <td>super good deal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2748</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IDQS</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>absolutely love card board used create literac...</td>\n",
       "      <td>must every teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2826</th>\n",
       "      <td>3.0</td>\n",
       "      <td>November 06, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IE7Y</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>still search perfect pen</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3245</th>\n",
       "      <td>5.0</td>\n",
       "      <td>August 05, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IEJC</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>really go wrong highlighter highly recommend</td>\n",
       "      <td>go wrong</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3326</th>\n",
       "      <td>5.0</td>\n",
       "      <td>October 18, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IEI7</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>much moaning groaning student decided buy elec...</td>\n",
       "      <td>typical pencil sharpener</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall         reviewTime      reviewerID        asin reviewerName                                         reviewText                   summary\n",
       "0         5.0      June 02, 2015  A1HBTW5M7ZZ9PT  0310818621        FTLOE  absolutely love organizer never one figured wa...           super good deal\n",
       "2748      5.0      June 17, 2016  A1HBTW5M7ZZ9PT  B00006IDQS        FTLOE  absolutely love card board used create literac...        must every teacher\n",
       "2826      3.0  November 06, 2016  A1HBTW5M7ZZ9PT  B00006IE7Y        FTLOE                           still search perfect pen                      okay\n",
       "3245      5.0    August 05, 2015  A1HBTW5M7ZZ9PT  B00006IEJC        FTLOE       really go wrong highlighter highly recommend                  go wrong\n",
       "3326      5.0   October 18, 2015  A1HBTW5M7ZZ9PT  B00006IEI7        FTLOE  much moaning groaning student decided buy elec...  typical pencil sharpener"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'A1HBTW5M7ZZ9PT'\n",
    "test_user = reviews_df[reviews_df['reviewerID'] == user_id]\n",
    "item_id = 'B00006IEI7'\n",
    "\n",
    "test_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: A1HBTW5M7ZZ9PT item: B00006IEI7 r_ui = 5.00   est = 4.93   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(user_id, item_id, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Collaborative Filtering setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# a first sketch of the NCF model\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, total_embed_length):\n",
    "        super(NCF, self).__init__()\n",
    "        self.total_embed_length = total_embed_length\n",
    "        \n",
    "        self.d1 = nn.Sequential(\n",
    "            nn.Linear(self.total_embed_length, 2048),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(2048)\n",
    "        )\n",
    "        \n",
    "        self.d2 = nn.Sequential(\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(1024)\n",
    "        )\n",
    "        \n",
    "        self.d3 = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.BatchNorm1d(512)\n",
    "        )\n",
    "        \n",
    "        self.d4 = nn.Linear(512, 256)\n",
    "        self.d5 = nn.Linear(256, 64)\n",
    "        self.d6 = nn.Linear(64, 16)\n",
    "        self.out = nn.Linear(16, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.d1(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.d3(x)\n",
    "        x = nn.ReLU()(self.d4(x))\n",
    "        x = nn.ReLU()(self.d5(x))\n",
    "        x = nn.ReLU()(self.d6(x))\n",
    "        out = nn.ReLU()(self.out(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# model training\n",
    "def train(model, dataset, criterion, optimizer, num_epochs, batch_size):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        num_batches = len(dataset) // batch_size\n",
    "        \n",
    "        for batch_idx in tqdm(range(num_batches)):\n",
    "            start_idx = batch_idx * batch_size\n",
    "            end_idx = start_idx + batch_size\n",
    "            \n",
    "            inputs = dataset[start_idx:end_idx, :-1].astype(np.float32)\n",
    "            labels = dataset[start_idx:end_idx, -1].astype(np.float32)\n",
    "            \n",
    "            inputs = torch.from_numpy(inputs)  # Convert inputs to PyTorch tensor\n",
    "            labels = torch.from_numpy(labels)  # Convert labels to PyTorch tensor\n",
    "            \n",
    "            optimizer.zero_grad()  # Clear the gradients\n",
    "            \n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, labels)  # Compute the loss\n",
    "            \n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update the weights\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / num_batches\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}\")\n",
    "    \n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30695, 800)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([user_embed_df, item_embed_df]).values\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/959 [00:00<?, ?it/s]/home/lucamodica/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/nn/modules/loss.py:535: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "100%|██████████| 959/959 [00:18<00:00, 52.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 959/959 [00:18<00:00, 51.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10, Loss: 0.0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 252/959 [00:05<00:14, 48.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m criterion \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mMSELoss()\n\u001b[1;32m      5\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m----> 7\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[68], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, dataset, criterion, optimizer, num_epochs, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)  \u001b[38;5;66;03m# Compute the loss\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()  \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Update the weights\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     31\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m running_loss \u001b[38;5;241m/\u001b[39m num_batches\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/optim/optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             )\n\u001b[0;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/optim/optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/optim/adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    158\u001b[0m         group,\n\u001b[1;32m    159\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    164\u001b[0m         state_steps)\n\u001b[0;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/optim/adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/design-ai/lib/python3.12/site-packages/torch/optim/adam.py:439\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    437\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (max_exp_avg_sqs[i]\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqrt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbias_correction2_sqrt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     param\u001b[38;5;241m.\u001b[39maddcdiv_(exp_avg, denom, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39mstep_size)\n\u001b[1;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = pd.concat([user_embed_df, item_embed_df]).values\n",
    "batch_size = 32\n",
    "model = NCF(799)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "train(model, data, criterion, optimizer, num_epochs=10, batch_size=batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
