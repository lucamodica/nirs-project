{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NIRS (model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils as utils\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import icecream as ic\n",
    "\n",
    "utils.seed_everything(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df = pd.read_csv('data/reviews_sampled_processed.csv')\n",
    "products_df = pd.read_csv('data/products_sampled_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "products_df = products_df.drop_duplicates(subset='asin', keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews df shape: (45538, 8)\n",
      "Products df shape: (34211, 41)\n"
     ]
    }
   ],
   "source": [
    "utils.print_shapes(reviews_df, products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique products: 34211\n",
      "Number of unique users: 1000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of unique products: {products_df[\"asin\"].nunique()}')\n",
    "print(f'Number of unique users: {reviews_df[\"reviewerID\"].nunique()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>April 09, 2016</td>\n",
       "      <td>A2GIQGI2UXOZ4M</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>Gene Sechrest</td>\n",
       "      <td>job big enough purpose fold flat fold stand gr...</td>\n",
       "      <td>ultimate kid magnetic board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>October 27, 2017</td>\n",
       "      <td>A2M13JN7YVG29U</td>\n",
       "      <td>0528960911</td>\n",
       "      <td>Stacie Baugh</td>\n",
       "      <td>love</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>December 31, 2014</td>\n",
       "      <td>A2ZVLGM9E6X2HY</td>\n",
       "      <td>0528960911</td>\n",
       "      <td>Michael Isgro</td>\n",
       "      <td>great money 15 look nice colorful</td>\n",
       "      <td>five star</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall         reviewTime      reviewerID        asin   reviewerName                                         reviewText                      summary\n",
       "0      5.0     April 09, 2016  A2GIQGI2UXOZ4M  0439893577  Gene Sechrest  job big enough purpose fold flat fold stand gr...  ultimate kid magnetic board\n",
       "1      5.0   October 27, 2017  A2M13JN7YVG29U  0528960911   Stacie Baugh                                               love                    five star\n",
       "2      5.0  December 31, 2014  A2ZVLGM9E6X2HY  0528960911  Michael Isgro                  great money 15 look nice colorful                    five star"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>productPublishedDate</th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rotect rfid card skimsafe card holder made rig...</td>\n",
       "      <td>Black RFID Blocking ID Badge Holder (Holds 2 C...</td>\n",
       "      <td>Specialist ID</td>\n",
       "      <td>rfid blocking 2 card holder fips 201 approved ...</td>\n",
       "      <td>43</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>October 14, 2011</td>\n",
       "      <td>B005VSY1VK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>itten piano key mouse pad 8 x 8 x 25 made heav...</td>\n",
       "      <td>3dRose LLC 8 x 8 x 0.25 Inches Kitten on Piano...</td>\n",
       "      <td>3dRose</td>\n",
       "      <td>dimension inch 8 w x 8 h x 025 matte finish so...</td>\n",
       "      <td>1</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>July 14, 2014</td>\n",
       "      <td>B00CX71JNU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ivo next favorite pen ultra gel stick vibrant ...</td>\n",
       "      <td>Vivo Ultra Gel Stick Pens, 0.7mm Fine Tip, Bla...</td>\n",
       "      <td>VIVO</td>\n",
       "      <td>ultra smooth gel ink vivid black amp color ful...</td>\n",
       "      <td>1</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>April 30, 2009</td>\n",
       "      <td>B002CO43BO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description                                              title          brand                                            feature  rank         main_cat productPublishedDate        asin\n",
       "0  rotect rfid card skimsafe card holder made rig...  Black RFID Blocking ID Badge Holder (Holds 2 C...  Specialist ID  rfid blocking 2 card holder fips 201 approved ...    43  Office Products     October 14, 2011  B005VSY1VK\n",
       "1  itten piano key mouse pad 8 x 8 x 25 made heav...  3dRose LLC 8 x 8 x 0.25 Inches Kitten on Piano...         3dRose  dimension inch 8 w x 8 h x 025 matte finish so...     1  Office Products        July 14, 2014  B00CX71JNU\n",
       "2  ivo next favorite pen ultra gel stick vibrant ...  Vivo Ultra Gel Stick Pens, 0.7mm Fine Tip, Bla...           VIVO  ultra smooth gel ink vivid black amp color ful...     1  Office Products       April 30, 2009  B002CO43BO"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>description</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>productPublishedDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>April 09, 2016</td>\n",
       "      <td>A2GIQGI2UXOZ4M</td>\n",
       "      <td>0439893577</td>\n",
       "      <td>Gene Sechrest</td>\n",
       "      <td>job big enough purpose fold flat fold stand gr...</td>\n",
       "      <td>ultimate kid magnetic board</td>\n",
       "      <td>agnetic tabletop learning easel one simplestye...</td>\n",
       "      <td>Little Red Tool Box: Magnetic Tabletop Learnin...</td>\n",
       "      <td>Scholastic</td>\n",
       "      <td>fold flat easy storage open reveal giant 12 x ...</td>\n",
       "      <td>21</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>November 25, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>October 27, 2017</td>\n",
       "      <td>A2M13JN7YVG29U</td>\n",
       "      <td>0528960911</td>\n",
       "      <td>Stacie Baugh</td>\n",
       "      <td>love</td>\n",
       "      <td>five star</td>\n",
       "      <td>yecatching 50 x 32 reference piece home classr...</td>\n",
       "      <td>Rand McNally M-Series Full-Color Laminated Uni...</td>\n",
       "      <td>Rand McNally</td>\n",
       "      <td>eyecatching 50 x 32 reference piece home class...</td>\n",
       "      <td>5</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>April 18, 2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>December 31, 2014</td>\n",
       "      <td>A2ZVLGM9E6X2HY</td>\n",
       "      <td>0528960911</td>\n",
       "      <td>Michael Isgro</td>\n",
       "      <td>great money 15 look nice colorful</td>\n",
       "      <td>five star</td>\n",
       "      <td>yecatching 50 x 32 reference piece home classr...</td>\n",
       "      <td>Rand McNally M-Series Full-Color Laminated Uni...</td>\n",
       "      <td>Rand McNally</td>\n",
       "      <td>eyecatching 50 x 32 reference piece home class...</td>\n",
       "      <td>5</td>\n",
       "      <td>Office Products</td>\n",
       "      <td>April 18, 2006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   overall         reviewTime      reviewerID        asin   reviewerName                                         reviewText                      summary                                        description                                              title         brand                                            feature  rank         main_cat productPublishedDate\n",
       "0      5.0     April 09, 2016  A2GIQGI2UXOZ4M  0439893577  Gene Sechrest  job big enough purpose fold flat fold stand gr...  ultimate kid magnetic board  agnetic tabletop learning easel one simplestye...  Little Red Tool Box: Magnetic Tabletop Learnin...    Scholastic  fold flat easy storage open reveal giant 12 x ...    21  Office Products    November 25, 2006\n",
       "1      5.0   October 27, 2017  A2M13JN7YVG29U  0528960911   Stacie Baugh                                               love                    five star  yecatching 50 x 32 reference piece home classr...  Rand McNally M-Series Full-Color Laminated Uni...  Rand McNally  eyecatching 50 x 32 reference piece home class...     5  Office Products       April 18, 2006\n",
       "2      5.0  December 31, 2014  A2ZVLGM9E6X2HY  0528960911  Michael Isgro                  great money 15 look nice colorful                    five star  yecatching 50 x 32 reference piece home classr...  Rand McNally M-Series Full-Color Laminated Uni...  Rand McNally  eyecatching 50 x 32 reference piece home class...     5  Office Products       April 18, 2006"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge the datasets\n",
    "df = pd.merge(reviews_df, products_df, on='asin', how='left')\n",
    "\n",
    "# Fill NaN values with appropriate values\n",
    "df['overall'] = df['overall'].fillna(0)  # Fill missing ratings with 0\n",
    "df['reviewerID'] = df['reviewerID'].fillna('Unknown')  # Fill missing user IDs with 'Unknown'\n",
    "df['asin'] = df['asin'].fillna('Unknown')  # Fill missing product IDs with 'Unknown'\n",
    "\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other data preparation for the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User and product id mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create user and item mappings\n",
    "user_mapping = {user_id: index for index, user_id in enumerate(df['reviewerID'].unique())}\n",
    "item_mapping = {item_id: index for index, item_id in enumerate(df['asin'].unique())}\n",
    "\n",
    "# Map user and item IDs to indices\n",
    "df['user_index'] = df['reviewerID'].map(user_mapping)\n",
    "df['item_index'] = df['asin'].map(item_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings (with Word2Vec or whatever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Create embeddings using Word2Vec\n",
    "def create_word2vec_embeddings(texts, embedding_dim):\n",
    "  # Tokenize the texts\n",
    "  tokenized_texts = [text.split() for text in texts]\n",
    "  \n",
    "  # Train Word2Vec model\n",
    "  model = Word2Vec(tokenized_texts, vector_size=embedding_dim, window=5, min_count=1, workers=4)\n",
    "  \n",
    "  # Get the embeddings for each text\n",
    "  embeddings = []\n",
    "  for text in tokenized_texts:\n",
    "      embedding = np.mean([model.wv[word] for word in text if word in model.wv], axis=0)\n",
    "      embeddings.append(embedding)\n",
    "  \n",
    "  return np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create embeddings for textual data\n",
    "# review_embeddings = create_word2vec_embeddings(df['reviewText'], embedding_dim=100)\n",
    "# title_embeddings = create_word2vec_embeddings(df['title'], embedding_dim=100)\n",
    "# description_embeddings = create_word2vec_embeddings(df['description'], embedding_dim=100)\n",
    "# summary_embeddings = create_word2vec_embeddings(df['summary'], embedding_dim=100)\n",
    "# feature_embeddings = create_word2vec_embeddings(df['feature'], embedding_dim=100)\n",
    "\n",
    "#load the embeddings\n",
    "review_embeddings = torch.load('data/embeds/review_embeddings.pt')\n",
    "summary_embeddings = torch.load('data/embeds/summary_embeddings.pt')\n",
    "description_embeddings = torch.load('data/embeds/description_embeddings.pt')\n",
    "title_embeddings = torch.load('data/embeds/title_embeddings.pt')\n",
    "feature_embeddings = torch.load('data/embeds/feature_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embed (SVD) from user-matrix pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the pivot table with the user-item interactions (reviews)\n",
    "user_product_matrix = pd.pivot_table(df, values='overall', index='reviewerID', columns='asin', fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVD_embeddings(user_item_matrix: pd.DataFrame, embedding_length):\n",
    "    \"\"\"\n",
    "    Apply SVD to the user-item matrix to obtain user and item embeddings.\n",
    "    U = m x r orthogonal left singular matrix, which represents the relationship between users and latent factors\n",
    "    S = r x r diagonal matrix, which describes the strength of each latent factor\n",
    "    V = r x n diagonal right singular matrix, which indicates the similarity between items and latent factors\n",
    "    \n",
    "    :param user_item_matrix: user-item matrix\n",
    "    :param embedding_length: number of latent factors, which is the dimensionality of the reduced space\n",
    "    \"\"\"\n",
    "    from scipy.sparse.linalg import svds\n",
    "    \n",
    "    # transpose the matrix to obtain the item-user matrix\n",
    "    # (this due to the large number of items compared to users)\n",
    "    matrix = user_item_matrix.values\n",
    "\n",
    "    U, Sigma, VT = svds(matrix, k=embedding_length)\n",
    "    user_embed_df = pd.DataFrame(U, index = user_item_matrix.index)\n",
    "    VT_T = np.transpose(VT)\n",
    "    item_embed_df = pd.DataFrame(VT_T, index=user_item_matrix.columns)\n",
    "    \n",
    "    return user_embed_df, item_embed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_embed_df, item_embed_df = SVD_embeddings(user_product_matrix, 800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reviews df shape: (999, 800)\n",
      "Products df shape: (8949, 800)\n"
     ]
    }
   ],
   "source": [
    "utils.print_shapes(user_embed_df, item_embed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader \n",
    "\n",
    "# class for the dataset\n",
    "class AmazonReviewDataset(Dataset):\n",
    "    def __init__(self, user_ids, item_ids, ratings, review_texts, product_titles, product_descriptions, review_summary, product_feature):\n",
    "        self.user_ids = user_ids\n",
    "        self.item_ids = item_ids\n",
    "        self.ratings = ratings\n",
    "        self.review_texts = review_texts\n",
    "        self.product_titles = product_titles\n",
    "        self.product_descriptions = product_descriptions\n",
    "        self.review_summary = review_summary\n",
    "        self.product_feature = product_feature\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        user_id = self.user_ids[index]\n",
    "        item_id = self.item_ids[index]\n",
    "        rating = self.ratings[index]\n",
    "        review_text = self.review_texts[index]\n",
    "        product_title = self.product_titles[index]\n",
    "        product_description = self.product_descriptions[index]\n",
    "        review_summary = self.review_summary[index]\n",
    "        product_feature = self.product_feature[index]\n",
    "        return user_id, item_id, rating, review_text, product_title, product_description, review_summary, product_feature\n",
    "\n",
    "# Split the data into train and test sets\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = AmazonReviewDataset(\n",
    "    train_data['user_index'].values,\n",
    "    train_data['item_index'].values,\n",
    "    train_data['overall'].values,\n",
    "    review_embeddings[train_data.index],\n",
    "    title_embeddings[train_data.index],\n",
    "    description_embeddings[train_data.index],\n",
    "    summary_embeddings[train_data.index],\n",
    "    feature_embeddings[train_data.index]\n",
    ")\n",
    "\n",
    "test_dataset = AmazonReviewDataset(\n",
    "    test_data['user_index'].values,\n",
    "    test_data['item_index'].values,\n",
    "    test_data['overall'].values,\n",
    "    review_embeddings[test_data.index],\n",
    "    title_embeddings[test_data.index],\n",
    "    description_embeddings[test_data.index],\n",
    "    summary_embeddings[test_data.index],\n",
    "    feature_embeddings[test_data.index]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vanilla SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A100WO06OQR8BQ and item B000034DLQ: 0.04106693642973573\n"
     ]
    }
   ],
   "source": [
    "# predictions with the the obrained SVD embeddings\n",
    "def predict_ratings(user_embed_df: pd.DataFrame, item_embed_df: pd.DataFrame, user_id: str, item_id: str):\n",
    "    \"\"\"\n",
    "    Predict the rating for a given user and item.\n",
    "    \n",
    "    :param user_embed_df: user embeddings\n",
    "    :param item_embed_df: item embeddings\n",
    "    :param user_id: user id\n",
    "    :param item_id: item id\n",
    "    \"\"\"\n",
    "    user_embedding = user_embed_df.loc[user_id]\n",
    "    item_embedding = item_embed_df.loc[item_id]\n",
    "    \n",
    "    \n",
    "    rating = np.dot(user_embedding, item_embedding)\n",
    "    return rating\n",
    "\n",
    "# example of prediction with a an item rated by a user\n",
    "user_id = user_product_matrix.index[0]\n",
    "\n",
    "# take the first product id rated by \"user_id\"\n",
    "# (thus an element that is not 0 in the user-product matrix)\n",
    "item_id = user_product_matrix.columns[user_product_matrix.loc[user_id] != 0].values[0]\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_ratings(user_embed_df, item_embed_df, user_id, item_id)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see if the predictions are consistent with the actual ratings\n",
    "actual_rating = user_product_matrix.loc[user_id, item_id]\n",
    "\n",
    "actual_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.06259022e-03,  3.36041414e-03,  2.10828465e-03, ...,\n",
       "        -5.92800395e-03, -4.63836032e-03,  1.60806135e-02],\n",
       "       [-8.41605637e-04, -3.90086343e-04, -1.16589769e-03, ...,\n",
       "        -2.46381296e-03,  2.20313593e-04, -1.21812485e-03],\n",
       "       [ 1.01916979e-03,  7.30603672e-04,  8.85298798e-04, ...,\n",
       "         3.49561297e-03,  2.78967836e-03, -1.13763659e-03],\n",
       "       ...,\n",
       "       [-1.54826132e-03, -2.46259024e-03,  6.40134527e-04, ...,\n",
       "        -2.05614460e-03,  1.64324585e-03,  1.51996888e-03],\n",
       "       [-5.38758957e-03,  3.14151719e-03, -5.97236288e-04, ...,\n",
       "        -7.48162225e-03,  4.57788905e-03,  3.94381031e-04],\n",
       "       [-1.47747455e-03,  5.56588897e-04,  2.46124572e-03, ...,\n",
       "        -1.68997541e-03, -1.07781086e-04,  6.34457891e-05]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(user_embed_df, item_embed_df.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick model test with SVD from scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick performance check of SVD by using scikit-surprise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.7310\n",
      "RMSE: 0.7168\n",
      "RMSE: 0.7304\n",
      "RMSE: 0.7056\n",
      "RMSE: 0.7210\n"
     ]
    }
   ],
   "source": [
    "from surprise import BaselineOnly, Dataset, SVD, Reader, accuracy, Trainset\n",
    "from surprise.model_selection import cross_validate, train_test_split, KFold\n",
    "\n",
    "# A reader is still needed but only the rating_scale param is requiered.\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data_test = Dataset.load_from_df(df[[\"reviewerID\", \"asin\", \"overall\"]], reader)\n",
    "\n",
    "# sample random trainset and testset\n",
    "# test set is made of 25% of the ratings.\n",
    "trainset, testset = train_test_split(data_test, test_size=0.25)\n",
    "\n",
    "# define a cross-validation iterator\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "algo = SVD()\n",
    "\n",
    "for trainset, testset in kf.split(data_test):\n",
    "\n",
    "    # train and test algorithm.\n",
    "    algo.fit(trainset)\n",
    "    predictions = algo.test(testset)\n",
    "\n",
    "    # Compute and print Root Mean Squared Error\n",
    "    accuracy.rmse(predictions, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IDQS</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>absolutely love card board used create literac...</td>\n",
       "      <td>must every teacher</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2184</th>\n",
       "      <td>3.0</td>\n",
       "      <td>November 06, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IE7Y</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>still search perfect pen</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>5.0</td>\n",
       "      <td>October 18, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IEI7</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>much moaning groaning student decided buy elec...</td>\n",
       "      <td>typical pencil sharpener</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3391</th>\n",
       "      <td>5.0</td>\n",
       "      <td>July 03, 2015</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IFEU</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>obsession sharpy use everything run crazy fast...</td>\n",
       "      <td>great buy sharpie lover</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3858</th>\n",
       "      <td>5.0</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>A1HBTW5M7ZZ9PT</td>\n",
       "      <td>B00006IFH6</td>\n",
       "      <td>FTLOE</td>\n",
       "      <td>bought chart marker could get planning done su...</td>\n",
       "      <td>solid buy teacher soak chart paper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall         reviewTime      reviewerID        asin reviewerName                                         reviewText                             summary\n",
       "2113      5.0      June 17, 2016  A1HBTW5M7ZZ9PT  B00006IDQS        FTLOE  absolutely love card board used create literac...                  must every teacher\n",
       "2184      3.0  November 06, 2016  A1HBTW5M7ZZ9PT  B00006IE7Y        FTLOE                           still search perfect pen                                okay\n",
       "2616      5.0   October 18, 2015  A1HBTW5M7ZZ9PT  B00006IEI7        FTLOE  much moaning groaning student decided buy elec...            typical pencil sharpener\n",
       "3391      5.0      July 03, 2015  A1HBTW5M7ZZ9PT  B00006IFEU        FTLOE  obsession sharpy use everything run crazy fast...             great buy sharpie lover\n",
       "3858      5.0      June 17, 2016  A1HBTW5M7ZZ9PT  B00006IFH6        FTLOE  bought chart marker could get planning done su...  solid buy teacher soak chart paper"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 'A1HBTW5M7ZZ9PT'\n",
    "test_user = reviews_df[reviews_df['reviewerID'] == user_id]\n",
    "item_id = 'B00006IEI7'\n",
    "\n",
    "test_user.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: A1HBTW5M7ZZ9PT item: B00006IEI7 r_ui = 5.00   est = 4.71   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# get a prediction for specific users and items.\n",
    "pred = algo.predict(user_id, item_id, r_ui=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Collaborative Filtering setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "# NCF model class\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim, hidden_dims, output_dim):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_dim = embedding_dim * 2\n",
    "        for hidden_dim in hidden_dims:\n",
    "            self.fc_layers.append(nn.Linear(input_dim, hidden_dim))\n",
    "            self.fc_layers.append(nn.ReLU())\n",
    "            input_dim = hidden_dim\n",
    "        self.output_layer = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_embeddings = self.user_embedding(user_ids)\n",
    "        item_embeddings = self.item_embedding(item_ids)\n",
    "        x = torch.cat([user_embeddings, item_embeddings], dim=1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = layer(x)\n",
    "        output = self.output_layer(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and evaluating functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the NCF model\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_model(model, dataloader, criterion, optimizer, device, num_epochs):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{num_epochs}\", unit=\"batch\")\n",
    "        for user_ids, item_ids, ratings, _, _, _, _, _ in progress_bar:\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            ratings = ratings.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            loss = criterion(outputs.squeeze(), ratings.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=running_loss / len(progress_bar))\n",
    "            \n",
    "        \n",
    "            \n",
    "# Evaluate the NCF model\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_ratings = []\n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Evaluating\", unit=\"batch\")\n",
    "        for user_ids, item_ids, ratings, _, _, _, _, _ in progress_bar:\n",
    "            user_ids = user_ids.to(device)\n",
    "            item_ids = item_ids.to(device)\n",
    "            outputs = model(user_ids, item_ids)\n",
    "            predictions.extend(outputs.squeeze().tolist())\n",
    "            true_ratings.extend(ratings.tolist())\n",
    "\n",
    "    mse = mean_squared_error(true_ratings, predictions)\n",
    "    mae = mean_absolute_error(true_ratings, predictions)\n",
    "    return mse, mae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 436/436 [00:02<00:00, 152.57batch/s, loss=2.51]\n",
      "Epoch 2/10: 100%|██████████| 436/436 [00:02<00:00, 153.56batch/s, loss=0.593]\n",
      "Epoch 3/10: 100%|██████████| 436/436 [00:03<00:00, 132.28batch/s, loss=0.492]\n",
      "Epoch 4/10: 100%|██████████| 436/436 [00:02<00:00, 148.68batch/s, loss=0.428]\n",
      "Epoch 5/10: 100%|██████████| 436/436 [00:02<00:00, 151.28batch/s, loss=0.376] \n",
      "Epoch 6/10: 100%|██████████| 436/436 [00:03<00:00, 144.01batch/s, loss=0.336] \n",
      "Epoch 7/10: 100%|██████████| 436/436 [00:02<00:00, 150.04batch/s, loss=0.298] \n",
      "Epoch 8/10: 100%|██████████| 436/436 [00:02<00:00, 154.47batch/s, loss=0.262] \n",
      "Epoch 9/10: 100%|██████████| 436/436 [00:03<00:00, 144.45batch/s, loss=0.227] \n",
      "Epoch 10/10: 100%|██████████| 436/436 [00:03<00:00, 144.12batch/s, loss=0.196] \n",
      "Evaluating: 100%|██████████| 109/109 [00:00<00:00, 1000.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test RMSE: 0.8393\n",
      "Test MAE: 0.6063\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Create the NCF model\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "embedding_dim = 100\n",
    "hidden_dims = [64, 32]\n",
    "output_dim = 1\n",
    "\n",
    "model = NCF(num_users, num_items, embedding_dim, hidden_dims, output_dim).to(device)\n",
    "\n",
    "# Define loss function (RMSE) and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "train_model(model, train_loader, criterion, optimizer, device, num_epochs)\n",
    "\n",
    "# Evaluate the model\n",
    "mse, mae = evaluate_model(model, test_loader, device)\n",
    "rmse = torch.sqrt(torch.tensor(mse))\n",
    "print(f\"\\nTest RMSE: {rmse:.4f}\")\n",
    "print(f\"Test MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model test with single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user A1HBTW5M7ZZ9PT and item B00006IEI7: 4.702612400054932\n",
      "Actual rating: 5.0\n",
      "Product info:                                              description                                 title   brand                                            feature  rank         main_cat productPublishedDate        asin\n",
      "18236  tylish powerful xacto xlr electric pencil shar...  X-ACTO XLR Electric Pencil Sharpener  X-Acto  stylish electric pencil sharpener ideal home o...     5  Office Products       April 18, 2006  B00006IEI7\n"
     ]
    }
   ],
   "source": [
    "def predict_score(user_id, item_id, model, user_mapping, item_mapping, device):\n",
    "    # Convert user ID and item ID to their corresponding indices\n",
    "    user_index = user_mapping[user_id]\n",
    "    item_index = item_mapping[item_id]\n",
    "\n",
    "    # Convert indices to tensors\n",
    "    user_tensor = torch.tensor([user_index], dtype=torch.long).to(device)\n",
    "    item_tensor = torch.tensor([item_index], dtype=torch.long).to(device)\n",
    "\n",
    "    # Get the predicted score from the model\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        score = model(user_tensor, item_tensor).item()\n",
    "\n",
    "    return score\n",
    "\n",
    "print(f'Predicted rating for user {user_id} and item {item_id}: {predict_score(user_id, item_id, model, user_mapping, item_mapping, device)}')\n",
    "print(f'Actual rating: {user_product_matrix.loc[user_id, item_id]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "design-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
